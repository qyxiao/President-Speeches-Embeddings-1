{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/shivamverma/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "# import chainer\n",
    "# from chainer import Function, gradient_check, report, training, utils, Variable\n",
    "# from chainer import datasets, iterators, optimizers, serializers\n",
    "# from chainer import Link, Chain, ChainList\n",
    "# import chainer.functions as F\n",
    "# import chainer.links as L\n",
    "# from chainer.training import extensions\n",
    "import os, sys, re\n",
    "from nltk import tokenize\n",
    "import nltk\n",
    "nltk.download('punkt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TEXT_DATA_DIR = './speech_data/data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 981 texts.\n"
     ]
    }
   ],
   "source": [
    "texts = []  # list of text samples\n",
    "# labels_index = {}  # dictionary mapping label name to numeric id\n",
    "# labels = []  # list of label ids\n",
    "for name in sorted(os.listdir(TEXT_DATA_DIR)):\n",
    "#     print name\n",
    "    path = os.path.join(TEXT_DATA_DIR, name)\n",
    "#     print path\n",
    "    if os.path.isdir(path):\n",
    "#         label_id = len(labels_index)\n",
    "#         labels_index[name] = label_id\n",
    "        for fname in sorted(os.listdir(path)):\n",
    "            if 'combined' not in fname and 'combines' not in fname:\n",
    "#                 print fname\n",
    "#             if fname.isdigit():\n",
    "                fpath = os.path.join(path, fname)\n",
    "                f = open(fpath)\n",
    "                texts.append(f.read())\n",
    "                f.close()\n",
    "#                 labels.append(label_id)\n",
    "\n",
    "print('Found %s texts.' % len(texts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Mr. Speaker, Mr. Vice President, my copartners in Government, gentlemen and ladies:   The Constitution imposes upon me the obligation to \"from time to time give to the Congress information of the State of the Union.\" While this has traditionally been interpreted as an annual affair, this tradition has been broken in extraordinary times.   These are extraordinary times. And we face an extraordinary challenge. Our strength as well as our convictions have imposed upon this nation the role of leader in freedom\\'s cause.   No role in history could be more difficult or more important. We stand for freedom. That is our conviction for ourselves\\xe2\\x80\\x94that is our only commitment to others. No friend, no neutral and no adversary should think otherwise. We are not against any man\\xe2\\x80\\x94or any nation\\xe2\\x80\\x94or any system\\xe2\\x80\\x94except as it is hostile to freedom. Nor am I here to present a new military doctrine, bearing any one name or aimed at any one area. I am here to promote the freedom doctrine.   The great battleground for the defense and expansion of freedom today is the whole southern half of the globe\\xe2\\x80\\x94Asia, Latin America, Africa and the Middle East\\xe2\\x80\\x94the lands of the rising peoples. Their revolution is the greatest in human history. They seek an end to injustice, tyranny, and exploitation.'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts[500][:1290]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def normalize_corpus(text, replace_period=False):\n",
    "    import string \n",
    "    \n",
    "    sents = tokenize.sent_tokenize(text.decode('utf8'))\n",
    "    sents = map(lambda x: x.replace('.',' '), sents)\n",
    "    text = ' . '.join(sents)\n",
    "        \n",
    "    for char in string.punctuation:\n",
    "        if not replace_period and char=='.':\n",
    "            text = text.replace(char, ' . ') #text.replace(char, ' ' + char + ' ')\n",
    "        else:\n",
    "            text = text.replace(char, ' ') #text.replace(char, ' ' + char + ' ')\n",
    "    \n",
    "    text = re.sub(r'[^\\x00-\\x7F]+',' ', text) #remove non-ASCII chars\n",
    "    text = re.sub( '\\s+', ' ', text).lstrip().rstrip() #remove extra and trailing spaces\n",
    "    \n",
    "    #\n",
    "    \n",
    "    return text.lower()\n",
    "\n",
    "norm_texts = map(lambda x: normalize_corpus(x), texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'mr speaker mr vice president my copartners in government gentlemen and ladies the constitution imposes upon me the obligation to from time to time give to the congress information of the state of the union . while this has traditionally been interpreted as an annual affair this tradition has been broken in extraordinary times . these are extraordinary times . and we face an extraordinary challenge . our strength as well as our convictions have imposed upon this nation the role of leader in freedom s cause . no role in history could be more difficult or more important . we stand for freedom . that is our conviction for ourselves that is our only commitment to others . no friend no neutral and no adversary should think otherwise . we are not against any man or any nation or any system except as it is hostile to freedom . nor am i here to present a new military doctrine bearing any one name or aimed at any one area . i am here to promote the freedom doctrine . the great battleground for the defense and expansion of freedom today is the whole southern half of the globe asia latin america africa and the middle east the lands of the rising peoples . their revolution is the greatest in human history . they seek an end to injustice tyranny and exploitation .'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "norm_texts[500][:1270]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# def normalize_corpus(text):\n",
    "#     import string \n",
    "    \n",
    "#     for char in string.punctuation:\n",
    "#         text = text.replace(char, ' ')#text.replace(char, ' ' + char + ' ')\n",
    "    \n",
    "#     text = re.sub(r'[^\\x00-\\x7F]+',' ', text) #remove non-ASCII chars\n",
    "#     text = re.sub( '\\s+', ' ', text).lstrip().rstrip() #remove extra and trailing spaces\n",
    "    \n",
    "#     return text.lower()\n",
    "\n",
    "# norm_texts = map(lambda x: normalize_corpus(x), texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "samp = norm_texts[500]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting sent and word frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_sent_lens(par):\n",
    "    sents = par.split(\".\")\n",
    "    return map(lambda x: len(x.lstrip().rstrip().split(\" \")), sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "224"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(get_sent_lens(samp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a.append(get_sent_lens(samp)[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sent_lens = []\n",
    "par_lens = []\n",
    "\n",
    "par_lens = map(lambda x: np.array(get_sent_lens(x)), norm_texts)\n",
    "par_arr = np.array(par_lens)\n",
    "#     sent_lens[ind].append(len(x.split(\".\")))\n",
    "#     par_lens.append(len(x.replace(\".\",\"\").split(\" \")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ array([ 79,  86,  30,  45,  54,  83,  22,  33,  14,  28,  57,  36,  51,\n",
       "        24,  52,  47,  51,  14, 113,  18,  34,   9,  24,  32,  16,  30,\n",
       "        42,  47,  38,  37, 116,  56,  26,  29, 728,  68,  53]),\n",
       "       array([ 47,  75, 104,  29,  45,  45,  79,  33,  59,  67,  21,  11,  41,\n",
       "        36,   7,  52,  40,  44,  51,  14,  47,  49,  35,  39,  51,  51,\n",
       "        60,   9,  94,  36,  25,  42,  10,  52,  32,  34,  16,  17,  34,\n",
       "        48,  36,  15,  49,  22,  59,  33,  54,  42,  38,  25,  24,  35,\n",
       "        44,  12,  29,  30,  20,  46,  49,  66,  25,  38,  54,  31,  33,\n",
       "        30,  40,  33,  54,  44,  59,  64,  77,  34]),\n",
       "       array([ 32,  42,  47,  37, 100,  21,  32,  45,  62,  38,  20,  38, 103,\n",
       "        11,   9,  13,  26,   9,  24,  50,  80,  25,  50,  14,  43,  52,\n",
       "        63, 101,  43,  45,  20,  47,  13,  40,  60, 116,  36,  19,  36,\n",
       "        12,  11,  11,  19,  11,  18,  25,  33,  69,  27,  50,  20,  12,\n",
       "        19,  37,  13]),\n",
       "       array([ 75, 141,  38,  42,  75,  30,  54,  87,  35,  94,  61,  20,  12,\n",
       "        48,  35,   9,  22,  29,  34,  51,  56,  39,  13,  20,  20,  28,\n",
       "        28,  46,  25,  32,  44,  15,  26, 112,  60, 120,  25, 114,  53,\n",
       "        32,  26,  44,  31,  66,  32, 119]),\n",
       "       array([ 17, 178,  68,  48,  29,  18,  15, 132,  18,  74,  35,  96,  27,\n",
       "       126,  69, 155,  43,  38,  44,  13,  98,  89,  28,  36]),\n",
       "       array([ 41,  23,  35,  33,  33,  10,  31,  15,  31,  40,  52,  22,  39,\n",
       "        72,  28,  16,  16,  26,   8,  46,  37,  46,  38,  39,  56, 134,\n",
       "        17,  18,  27,  16,  32,  38,  25,  37,  31,  29,  84,  53]),\n",
       "       array([208, 321,  82,  34,   2,   8]),\n",
       "       array([55, 22,  2,  5,  6, 22, 18, 21, 33, 10, 22, 16, 20, 90, 26,  9,  8,\n",
       "       16,  5, 15, 14, 24,  8, 17, 12, 13, 16, 19, 17, 11, 13,  7,  7, 14,\n",
       "       17, 20,  8,  3, 12, 41, 64, 36, 59, 24, 29, 31, 17, 11, 16, 10, 36,\n",
       "       35, 16,  2, 88, 12, 41, 22,  2]),\n",
       "       array([252,  37,   2]),\n",
       "       array([18, 51, 28, 27, 12, 46, 85,  4, 13, 31, 15, 19, 45, 39])], dtype=object)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "par_arr[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 79,  86,  30,  45,  54,  83,  22,  33,  14,  28,  57,  36,  51,\n",
       "        24,  52,  47,  51,  14, 113,  18,  34,   9,  24,  32,  16,  30,\n",
       "        42,  47,  38,  37, 116,  56,  26,  29, 728,  68,  53])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "par_arr[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 3, 4, 5, 6])"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array([[1,2,3],[4,5,6]]).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37\n",
      "74\n",
      "55\n",
      "46\n",
      "24\n",
      "38\n",
      "6\n",
      "59\n",
      "3\n",
      "14\n"
     ]
    }
   ],
   "source": [
    "for x in par_arr[:10]:\n",
    "    print len(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sent_freq = []\n",
    "for x in par_arr:\n",
    "    sent_freq.append(len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "981"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sent_freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(map(lambda x: x > 400, sent_freq)) #sorted(sent_freq, reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 113.,   85.,   75.,   62.,   61.,   48.,   42.,   28.,   32.,\n",
       "          38.,   36.,   35.,   46.,   28.,   30.,   23.,   33.,   20.,\n",
       "          13.,    4.,   10.,    9.,   13.,    7.,    6.,    7.,    6.,\n",
       "           3.,    5.,    4.,    7.,    5.,    4.,    5.,    1.,    4.,\n",
       "           2.,    1.,    3.,    2.,    2.,    2.,    0.,    5.,    1.,\n",
       "           2.,    0.,    1.,    2.,    1.,    0.,    0.,    2.,    0.,\n",
       "           0.,    0.,    1.,    0.,    0.,    0.,    0.,    1.,    0.,\n",
       "           0.,    0.,    0.,    0.,    2.,    0.,    0.,    0.,    0.,\n",
       "           0.,    1.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.,    0.,    0.,    0.,    0.,    1.,    0.,    0.,    0.,\n",
       "           0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    1.]),\n",
       " array([  1.00000000e+00,   1.31200000e+01,   2.52400000e+01,\n",
       "          3.73600000e+01,   4.94800000e+01,   6.16000000e+01,\n",
       "          7.37200000e+01,   8.58400000e+01,   9.79600000e+01,\n",
       "          1.10080000e+02,   1.22200000e+02,   1.34320000e+02,\n",
       "          1.46440000e+02,   1.58560000e+02,   1.70680000e+02,\n",
       "          1.82800000e+02,   1.94920000e+02,   2.07040000e+02,\n",
       "          2.19160000e+02,   2.31280000e+02,   2.43400000e+02,\n",
       "          2.55520000e+02,   2.67640000e+02,   2.79760000e+02,\n",
       "          2.91880000e+02,   3.04000000e+02,   3.16120000e+02,\n",
       "          3.28240000e+02,   3.40360000e+02,   3.52480000e+02,\n",
       "          3.64600000e+02,   3.76720000e+02,   3.88840000e+02,\n",
       "          4.00960000e+02,   4.13080000e+02,   4.25200000e+02,\n",
       "          4.37320000e+02,   4.49440000e+02,   4.61560000e+02,\n",
       "          4.73680000e+02,   4.85800000e+02,   4.97920000e+02,\n",
       "          5.10040000e+02,   5.22160000e+02,   5.34280000e+02,\n",
       "          5.46400000e+02,   5.58520000e+02,   5.70640000e+02,\n",
       "          5.82760000e+02,   5.94880000e+02,   6.07000000e+02,\n",
       "          6.19120000e+02,   6.31240000e+02,   6.43360000e+02,\n",
       "          6.55480000e+02,   6.67600000e+02,   6.79720000e+02,\n",
       "          6.91840000e+02,   7.03960000e+02,   7.16080000e+02,\n",
       "          7.28200000e+02,   7.40320000e+02,   7.52440000e+02,\n",
       "          7.64560000e+02,   7.76680000e+02,   7.88800000e+02,\n",
       "          8.00920000e+02,   8.13040000e+02,   8.25160000e+02,\n",
       "          8.37280000e+02,   8.49400000e+02,   8.61520000e+02,\n",
       "          8.73640000e+02,   8.85760000e+02,   8.97880000e+02,\n",
       "          9.10000000e+02,   9.22120000e+02,   9.34240000e+02,\n",
       "          9.46360000e+02,   9.58480000e+02,   9.70600000e+02,\n",
       "          9.82720000e+02,   9.94840000e+02,   1.00696000e+03,\n",
       "          1.01908000e+03,   1.03120000e+03,   1.04332000e+03,\n",
       "          1.05544000e+03,   1.06756000e+03,   1.07968000e+03,\n",
       "          1.09180000e+03,   1.10392000e+03,   1.11604000e+03,\n",
       "          1.12816000e+03,   1.14028000e+03,   1.15240000e+03,\n",
       "          1.16452000e+03,   1.17664000e+03,   1.18876000e+03,\n",
       "          1.20088000e+03,   1.21300000e+03]),\n",
       " <a list of 100 Patch objects>)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAe0AAAFVCAYAAADCLbfjAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nCEIbAABDENoAABiC0AYAwBD/D1fcBplFqbklAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11c516150>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(sent_freq,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1213\n"
     ]
    }
   ],
   "source": [
    "maxi = 0\n",
    "for x in par_arr:\n",
    "    if len(x) > maxi:\n",
    "        maxi = len(x)\n",
    "print maxi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ array([ 79,  86,  30,  45,  54,  83,  22,  33,  14,  28,  57,  36,  51,\n",
       "        24,  52,  47,  51,  14, 113,  18,  34,   9,  24,  32,  16,  30,\n",
       "        42,  47,  38,  37, 116,  56,  26,  29, 728,  68,  53]),\n",
       "       array([ 47,  75, 104,  29,  45,  45,  79,  33,  59,  67,  21,  11,  41,\n",
       "        36,   7,  52,  40,  44,  51,  14,  47,  49,  35,  39,  51,  51,\n",
       "        60,   9,  94,  36,  25,  42,  10,  52,  32,  34,  16,  17,  34,\n",
       "        48,  36,  15,  49,  22,  59,  33,  54,  42,  38,  25,  24,  35,\n",
       "        44,  12,  29,  30,  20,  46,  49,  66,  25,  38,  54,  31,  33,\n",
       "        30,  40,  33,  54,  44,  59,  64,  77,  34]),\n",
       "       array([ 32,  42,  47,  37, 100,  21,  32,  45,  62,  38,  20,  38, 103,\n",
       "        11,   9,  13,  26,   9,  24,  50,  80,  25,  50,  14,  43,  52,\n",
       "        63, 101,  43,  45,  20,  47,  13,  40,  60, 116,  36,  19,  36,\n",
       "        12,  11,  11,  19,  11,  18,  25,  33,  69,  27,  50,  20,  12,\n",
       "        19,  37,  13]),\n",
       "       array([ 75, 141,  38,  42,  75,  30,  54,  87,  35,  94,  61,  20,  12,\n",
       "        48,  35,   9,  22,  29,  34,  51,  56,  39,  13,  20,  20,  28,\n",
       "        28,  46,  25,  32,  44,  15,  26, 112,  60, 120,  25, 114,  53,\n",
       "        32,  26,  44,  31,  66,  32, 119]),\n",
       "       array([ 17, 178,  68,  48,  29,  18,  15, 132,  18,  74,  35,  96,  27,\n",
       "       126,  69, 155,  43,  38,  44,  13,  98,  89,  28,  36])], dtype=object)"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "par_arr[:5].flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "224"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(samp.split(\".\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 79,  86,  30,  45,  54,  83,  22,  33,  14,  28,  57,  36,  51,\n",
       "        24,  52,  47,  51,  14, 113,  18,  34,   9,  24,  32,  16,  30,\n",
       "        42,  47,  38,  37, 116,  56,  26,  29, 728,  68,  53])"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "par_arr[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pad_to_dense(M, maxlen):\n",
    "\n",
    "    Z = np.zeros((len(M), maxlen))\n",
    "    for enu, row in enumerate(M):\n",
    "        Z[enu, :len(row)] += row[:maxlen]\n",
    "    return Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  79.,   86.,   30.,   45.,   54.,   83.,   22.,   33.,   14.,\n",
       "          28.,   57.,   36.,   51.,   24.,   52.,   47.,   51.,   14.,\n",
       "         113.,   18.,   34.,    9.,   24.,   32.,   16.,   30.,   42.,\n",
       "          47.,   38.,   37.,  116.,   56.,   26.,   29.,  728.,   68.,\n",
       "          53.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.,    0.,    0.,    0.,    0.],\n",
       "       [  47.,   75.,  104.,   29.,   45.,   45.,   79.,   33.,   59.,\n",
       "          67.,   21.,   11.,   41.,   36.,    7.,   52.,   40.,   44.,\n",
       "          51.,   14.,   47.,   49.,   35.,   39.,   51.,   51.,   60.,\n",
       "           9.,   94.,   36.,   25.,   42.,   10.,   52.,   32.,   34.,\n",
       "          16.,   17.,   34.,   48.,   36.,   15.,   49.,   22.,   59.,\n",
       "          33.,   54.,   42.,   38.,   25.],\n",
       "       [  32.,   42.,   47.,   37.,  100.,   21.,   32.,   45.,   62.,\n",
       "          38.,   20.,   38.,  103.,   11.,    9.,   13.,   26.,    9.,\n",
       "          24.,   50.,   80.,   25.,   50.,   14.,   43.,   52.,   63.,\n",
       "         101.,   43.,   45.,   20.,   47.,   13.,   40.,   60.,  116.,\n",
       "          36.,   19.,   36.,   12.,   11.,   11.,   19.,   11.,   18.,\n",
       "          25.,   33.,   69.,   27.,   50.],\n",
       "       [  75.,  141.,   38.,   42.,   75.,   30.,   54.,   87.,   35.,\n",
       "          94.,   61.,   20.,   12.,   48.,   35.,    9.,   22.,   29.,\n",
       "          34.,   51.,   56.,   39.,   13.,   20.,   20.,   28.,   28.,\n",
       "          46.,   25.,   32.,   44.,   15.,   26.,  112.,   60.,  120.,\n",
       "          25.,  114.,   53.,   32.,   26.,   44.,   31.,   66.,   32.,\n",
       "         119.,    0.,    0.,    0.,    0.],\n",
       "       [  17.,  178.,   68.,   48.,   29.,   18.,   15.,  132.,   18.,\n",
       "          74.,   35.,   96.,   27.,  126.,   69.,  155.,   43.,   38.,\n",
       "          44.,   13.,   98.,   89.,   28.,   36.,    0.,    0.,    0.,\n",
       "           0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.,    0.,    0.,    0.,    0.]])"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pad_to_dense(par_arr[:5], 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 79,  86,  30,  45,  54,  83,  22,  33,  14,  28,  57,  36,  51,\n",
       "        24,  52,  47,  51,  14, 113,  18,  34,   9,  24,  32,  16,  30,\n",
       "        42,  47,  38,  37, 116,  56,  26,  29, 728,  68,  53,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0])"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.pad(par_arr[0],((0,10),), 'constant')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 1.,  1.],\n",
       "        [ 1.,  1.],\n",
       "        [ 1.,  1.]],\n",
       "\n",
       "       [[ 1.,  1.],\n",
       "        [ 1.,  1.],\n",
       "        [ 1.,  1.]],\n",
       "\n",
       "       [[ 1.,  1.],\n",
       "        [ 1.,  1.],\n",
       "        [ 1.,  1.]],\n",
       "\n",
       "       [[ 1.,  1.],\n",
       "        [ 1.,  1.],\n",
       "        [ 1.,  1.]]])"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.ones((4, 3, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'int' object has no attribute 'rint'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-121-6aea4c5d075d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpar_arr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'maximum'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/numpy/lib/arraypad.pyc\u001b[0m in \u001b[0;36mpad\u001b[0;34m(array, pad_width, mode, **kwargs)\u001b[0m\n\u001b[1;32m   1316\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1317\u001b[0m     \u001b[0mnarray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1318\u001b[0;31m     \u001b[0mpad_width\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_validate_lengths\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnarray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpad_width\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1319\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1320\u001b[0m     allowedkwargs = {\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/numpy/lib/arraypad.pyc\u001b[0m in \u001b[0;36m_validate_lengths\u001b[0;34m(narray, number_elements)\u001b[0m\n\u001b[1;32m   1101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m     \"\"\"\n\u001b[0;32m-> 1103\u001b[0;31m     \u001b[0mnormshp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_normalize_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnarray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumber_elements\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1104\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnormshp\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1105\u001b[0m         \u001b[0mchk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/numpy/lib/arraypad.pyc\u001b[0m in \u001b[0;36m_normalize_shape\u001b[0;34m(ndarray, shape, cast_to_int)\u001b[0m\n\u001b[1;32m   1064\u001b[0m     \u001b[0;31m# Cast if necessary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1065\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcast_to_int\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1066\u001b[0;31m         \u001b[0marr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1067\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1068\u001b[0m     \u001b[0;31m# Convert list of lists to tuple of tuples\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/numpy/core/fromnumeric.pyc\u001b[0m in \u001b[0;36mround_\u001b[0;34m(a, decimals, out)\u001b[0m\n\u001b[1;32m   2791\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2792\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_wrapit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'round'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecimals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2793\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecimals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2794\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2795\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'int' object has no attribute 'rint'"
     ]
    }
   ],
   "source": [
    "np.pad(par_arr[:5], 50, 'maximum')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "character mapping must return integer, None or unicode",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-34-2dd9a3d7662f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnb_words\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mMAX_NB_WORDS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_on_texts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtexts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0msequences\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtexts_to_sequences\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnorm_texts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/keras/preprocessing/text.pyc\u001b[0m in \u001b[0;36mtexts_to_sequences\u001b[0;34m(self, texts)\u001b[0m\n\u001b[1;32m    129\u001b[0m         '''\n\u001b[1;32m    130\u001b[0m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mvect\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtexts_to_sequences_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtexts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m             \u001b[0mres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvect\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/keras/preprocessing/text.pyc\u001b[0m in \u001b[0;36mtexts_to_sequences_generator\u001b[0;34m(self, texts)\u001b[0m\n\u001b[1;32m    145\u001b[0m         \u001b[0mnb_words\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnb_words\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtext\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtexts\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m             \u001b[0mseq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtext\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchar_level\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mtext_to_word_sequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    148\u001b[0m             \u001b[0mvect\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mseq\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/keras/preprocessing/text.pyc\u001b[0m in \u001b[0;36mtext_to_word_sequence\u001b[0;34m(text, filters, lower, split)\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlower\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m     \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranslate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaketrans\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msplit\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m     \u001b[0mseq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0m_f\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_f\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mseq\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m_f\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: character mapping must return integer, None or unicode"
     ]
    }
   ],
   "source": [
    "MAX_NB_WORDS = None\n",
    "\n",
    "tokenizer = Tokenizer(nb_words=MAX_NB_WORDS)\n",
    "tokenizer.fit_on_texts(texts)\n",
    "sequences = tokenizer.texts_to_sequences(norm_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3,\n",
       " 1,\n",
       " 252,\n",
       " 2,\n",
       " 1,\n",
       " 41,\n",
       " 34,\n",
       " 14,\n",
       " 3324,\n",
       " 1676,\n",
       " 3,\n",
       " 1,\n",
       " 252,\n",
       " 9,\n",
       " 284,\n",
       " 19,\n",
       " 6,\n",
       " 319,\n",
       " 3,\n",
       " 1961,\n",
       " 6,\n",
       " 183,\n",
       " 1229,\n",
       " 24,\n",
       " 1,\n",
       " 1499,\n",
       " 2,\n",
       " 1178,\n",
       " 19,\n",
       " 1,\n",
       " 327,\n",
       " 2,\n",
       " 1552,\n",
       " 758,\n",
       " 9,\n",
       " 1,\n",
       " 519,\n",
       " 2,\n",
       " 37,\n",
       " 5931,\n",
       " 813,\n",
       " 643,\n",
       " 1,\n",
       " 285,\n",
       " 2,\n",
       " 7,\n",
       " 91,\n",
       " 1,\n",
       " 1248,\n",
       " 2,\n",
       " 17,\n",
       " 183,\n",
       " 33,\n",
       " 1234,\n",
       " 61,\n",
       " 83,\n",
       " 6,\n",
       " 1467,\n",
       " 7,\n",
       " 11,\n",
       " 33,\n",
       " 5820,\n",
       " 1897,\n",
       " 16,\n",
       " 1,\n",
       " 127,\n",
       " 4,\n",
       " 167,\n",
       " 232,\n",
       " 4,\n",
       " 1075,\n",
       " 208,\n",
       " 2,\n",
       " 1,\n",
       " 41,\n",
       " 34,\n",
       " 1,\n",
       " 620,\n",
       " 2,\n",
       " 833,\n",
       " 1005,\n",
       " 114,\n",
       " 1,\n",
       " 1190,\n",
       " 4,\n",
       " 627,\n",
       " 3129,\n",
       " 2,\n",
       " 1,\n",
       " 147,\n",
       " 8,\n",
       " 6,\n",
       " 497,\n",
       " 1,\n",
       " 2210,\n",
       " 2,\n",
       " 20,\n",
       " 274,\n",
       " 159,\n",
       " 1,\n",
       " 285,\n",
       " 2,\n",
       " 1,\n",
       " 41,\n",
       " 34,\n",
       " 8,\n",
       " 6,\n",
       " 2412,\n",
       " 8196,\n",
       " 172,\n",
       " 1,\n",
       " 786,\n",
       " 2,\n",
       " 12,\n",
       " 132,\n",
       " 25,\n",
       " 4108,\n",
       " 3,\n",
       " 1,\n",
       " 185,\n",
       " 2,\n",
       " 1831,\n",
       " 196,\n",
       " 2,\n",
       " 2512,\n",
       " 2404,\n",
       " 16,\n",
       " 6817,\n",
       " 114,\n",
       " 1,\n",
       " 126,\n",
       " 3383,\n",
       " 47,\n",
       " 73,\n",
       " 3404,\n",
       " 22,\n",
       " 2224,\n",
       " 3,\n",
       " 842,\n",
       " 6,\n",
       " 97,\n",
       " 175,\n",
       " 2463,\n",
       " 2,\n",
       " 119,\n",
       " 147,\n",
       " 4,\n",
       " 372,\n",
       " 9,\n",
       " 27,\n",
       " 2143,\n",
       " 509,\n",
       " 1,\n",
       " 34,\n",
       " 61,\n",
       " 1,\n",
       " 627,\n",
       " 22,\n",
       " 44,\n",
       " 1514,\n",
       " 30,\n",
       " 60,\n",
       " 61,\n",
       " 1,\n",
       " 1190,\n",
       " 64,\n",
       " 54,\n",
       " 3366,\n",
       " 16,\n",
       " 346,\n",
       " 1406,\n",
       " 532,\n",
       " 377,\n",
       " 4,\n",
       " 1122,\n",
       " 22,\n",
       " 6099,\n",
       " 3,\n",
       " 76,\n",
       " 1275,\n",
       " 4,\n",
       " 882,\n",
       " 6099,\n",
       " 3,\n",
       " 1365,\n",
       " 64,\n",
       " 22,\n",
       " 47,\n",
       " 126,\n",
       " 73,\n",
       " 34,\n",
       " 3,\n",
       " 166,\n",
       " 55,\n",
       " 16,\n",
       " 872,\n",
       " 1380,\n",
       " 2,\n",
       " 3657,\n",
       " 7035,\n",
       " 28,\n",
       " 398,\n",
       " 83,\n",
       " 6919,\n",
       " 22,\n",
       " 5437,\n",
       " 5,\n",
       " 1,\n",
       " 1193,\n",
       " 564,\n",
       " 1,\n",
       " 13307,\n",
       " 19,\n",
       " 1,\n",
       " 4939,\n",
       " 2,\n",
       " 14874,\n",
       " 25549,\n",
       " 1376,\n",
       " 28,\n",
       " 8740,\n",
       " 1,\n",
       " 1226,\n",
       " 2,\n",
       " 1,\n",
       " 8293,\n",
       " 2,\n",
       " 21074,\n",
       " 6,\n",
       " 104,\n",
       " 186,\n",
       " 1053,\n",
       " 42,\n",
       " 21,\n",
       " 756,\n",
       " 1958,\n",
       " 19,\n",
       " 58,\n",
       " 6,\n",
       " 3603,\n",
       " 2,\n",
       " 40,\n",
       " 3751,\n",
       " 2028,\n",
       " 353,\n",
       " 13,\n",
       " 1927,\n",
       " 37,\n",
       " 1406,\n",
       " 1641,\n",
       " 2,\n",
       " 4621,\n",
       " 123,\n",
       " 592,\n",
       " 95,\n",
       " 1108,\n",
       " 24,\n",
       " 1,\n",
       " 1190,\n",
       " 4,\n",
       " 1712,\n",
       " 2,\n",
       " 328,\n",
       " 4,\n",
       " 522,\n",
       " 2744,\n",
       " 2,\n",
       " 88,\n",
       " 592,\n",
       " 95,\n",
       " 1108,\n",
       " 24,\n",
       " 1,\n",
       " 627,\n",
       " 159,\n",
       " 6,\n",
       " 927,\n",
       " 1,\n",
       " 778,\n",
       " 734,\n",
       " 25,\n",
       " 1504,\n",
       " 96,\n",
       " 37,\n",
       " 1688,\n",
       " 19,\n",
       " 6,\n",
       " 245,\n",
       " 4,\n",
       " 1442,\n",
       " 701,\n",
       " 637,\n",
       " 19,\n",
       " 859,\n",
       " 31,\n",
       " 5006,\n",
       " 1504,\n",
       " 433,\n",
       " 32,\n",
       " 1,\n",
       " 127,\n",
       " 526,\n",
       " 2,\n",
       " 205,\n",
       " 1,\n",
       " 246,\n",
       " 2,\n",
       " 1,\n",
       " 534,\n",
       " 23,\n",
       " 209,\n",
       " 67,\n",
       " 6,\n",
       " 6013,\n",
       " 2,\n",
       " 861,\n",
       " 498,\n",
       " 1185,\n",
       " 95,\n",
       " 95,\n",
       " 1422,\n",
       " 2,\n",
       " 20,\n",
       " 1,\n",
       " 546,\n",
       " 49,\n",
       " 15,\n",
       " 6,\n",
       " 4621,\n",
       " 1088,\n",
       " 4,\n",
       " 7057,\n",
       " 1528,\n",
       " 64,\n",
       " 57,\n",
       " 4446,\n",
       " 59,\n",
       " 104,\n",
       " 5,\n",
       " 208,\n",
       " 4,\n",
       " 4246,\n",
       " 1,\n",
       " 528,\n",
       " 4,\n",
       " 1,\n",
       " 546,\n",
       " 22,\n",
       " 44,\n",
       " 3246,\n",
       " 22944,\n",
       " 9,\n",
       " 27,\n",
       " 509,\n",
       " 2,\n",
       " 695,\n",
       " 4,\n",
       " 3219,\n",
       " 787,\n",
       " 16,\n",
       " 833,\n",
       " 4,\n",
       " 2,\n",
       " 119,\n",
       " 314,\n",
       " 118,\n",
       " 2143,\n",
       " 944,\n",
       " 64,\n",
       " 22,\n",
       " 97,\n",
       " 2,\n",
       " 1,\n",
       " 1856,\n",
       " 2,\n",
       " 55,\n",
       " 242,\n",
       " 30,\n",
       " 26,\n",
       " 2609,\n",
       " 62,\n",
       " 1,\n",
       " 488,\n",
       " 2,\n",
       " 1906,\n",
       " 58,\n",
       " 833,\n",
       " 1005,\n",
       " 25,\n",
       " 150,\n",
       " 6027,\n",
       " 255,\n",
       " 107,\n",
       " 1976,\n",
       " 15,\n",
       " 29,\n",
       " 1600,\n",
       " 4,\n",
       " 3470,\n",
       " 15,\n",
       " 29,\n",
       " 77,\n",
       " 2,\n",
       " 27,\n",
       " 262,\n",
       " 997,\n",
       " 2570,\n",
       " 18,\n",
       " 6,\n",
       " 874,\n",
       " 2,\n",
       " 1,\n",
       " 363,\n",
       " 40323,\n",
       " 369,\n",
       " 2,\n",
       " 1,\n",
       " 1625,\n",
       " 33,\n",
       " 2692,\n",
       " 10358,\n",
       " 1045,\n",
       " 5,\n",
       " 59,\n",
       " 332,\n",
       " 4,\n",
       " 256,\n",
       " 1041,\n",
       " 2214,\n",
       " 315,\n",
       " 16,\n",
       " 6,\n",
       " 711,\n",
       " 2,\n",
       " 3688,\n",
       " 86,\n",
       " 126,\n",
       " 2570,\n",
       " 2390,\n",
       " 159,\n",
       " 1640,\n",
       " 2,\n",
       " 3177,\n",
       " 2185,\n",
       " 59,\n",
       " 16,\n",
       " 148,\n",
       " 2,\n",
       " 765,\n",
       " 4,\n",
       " 1,\n",
       " 55,\n",
       " 643,\n",
       " 1552,\n",
       " 1,\n",
       " 183,\n",
       " 57,\n",
       " 969,\n",
       " 125,\n",
       " 38,\n",
       " 1659,\n",
       " 9,\n",
       " 58,\n",
       " 6,\n",
       " 5313,\n",
       " 138,\n",
       " 1,\n",
       " 706,\n",
       " 285,\n",
       " 2,\n",
       " 1552,\n",
       " 14,\n",
       " 1469,\n",
       " 92,\n",
       " 373,\n",
       " 255,\n",
       " 3,\n",
       " 1,\n",
       " 458,\n",
       " 2,\n",
       " 1,\n",
       " 470,\n",
       " 322,\n",
       " 18,\n",
       " 217,\n",
       " 23201,\n",
       " 40,\n",
       " 2759,\n",
       " 30,\n",
       " 376,\n",
       " 3,\n",
       " 1,\n",
       " 670,\n",
       " 1498,\n",
       " 2,\n",
       " 1,\n",
       " 327,\n",
       " 138,\n",
       " 371,\n",
       " 624,\n",
       " 1,\n",
       " 2482,\n",
       " 42,\n",
       " 532,\n",
       " 10,\n",
       " 2141,\n",
       " 1,\n",
       " 2739,\n",
       " 2,\n",
       " 1,\n",
       " 183,\n",
       " 423,\n",
       " 3,\n",
       " 1,\n",
       " 3501,\n",
       " 1343,\n",
       " 4,\n",
       " 334,\n",
       " 2,\n",
       " 6796,\n",
       " 165,\n",
       " 5,\n",
       " 1,\n",
       " 4953,\n",
       " 1,\n",
       " 41,\n",
       " 34,\n",
       " 15,\n",
       " 48,\n",
       " 3304,\n",
       " 28,\n",
       " 494,\n",
       " 9,\n",
       " 1468,\n",
       " 2649,\n",
       " 28,\n",
       " 232,\n",
       " 268,\n",
       " 504,\n",
       " 1,\n",
       " 127,\n",
       " 1613,\n",
       " 4,\n",
       " 841,\n",
       " 58,\n",
       " 8,\n",
       " 2070,\n",
       " 16,\n",
       " 17,\n",
       " 183,\n",
       " 1,\n",
       " 126,\n",
       " 295,\n",
       " 2255,\n",
       " 5,\n",
       " 6617,\n",
       " 17,\n",
       " 2737,\n",
       " 18,\n",
       " 1,\n",
       " 2999,\n",
       " 196,\n",
       " 16,\n",
       " 20,\n",
       " 1,\n",
       " 110,\n",
       " 18,\n",
       " 1786,\n",
       " 3,\n",
       " 1,\n",
       " 59,\n",
       " 18,\n",
       " 3,\n",
       " 1,\n",
       " 55,\n",
       " 42,\n",
       " 10,\n",
       " 1025,\n",
       " 83,\n",
       " 58,\n",
       " 525,\n",
       " 18,\n",
       " 3,\n",
       " 436,\n",
       " 1478,\n",
       " 1,\n",
       " 2238,\n",
       " 2,\n",
       " 738,\n",
       " 114,\n",
       " 51,\n",
       " 4,\n",
       " 2,\n",
       " 1673,\n",
       " 30,\n",
       " 113,\n",
       " 1,\n",
       " 813,\n",
       " 8,\n",
       " 3832,\n",
       " 6,\n",
       " 563,\n",
       " 196,\n",
       " 2,\n",
       " 833,\n",
       " 1005,\n",
       " 114,\n",
       " 1,\n",
       " 1190,\n",
       " 4,\n",
       " 627,\n",
       " 2102,\n",
       " 2,\n",
       " 1,\n",
       " 126,\n",
       " 211,\n",
       " 20,\n",
       " 2255,\n",
       " 9,\n",
       " 40,\n",
       " 519,\n",
       " 1,\n",
       " 59,\n",
       " 4149,\n",
       " 1,\n",
       " 285,\n",
       " 4,\n",
       " 1,\n",
       " 55,\n",
       " 3820,\n",
       " 1,\n",
       " 259,\n",
       " 4954,\n",
       " 3559,\n",
       " 1,\n",
       " 1233,\n",
       " 20,\n",
       " 1,\n",
       " 1458,\n",
       " 251,\n",
       " 69,\n",
       " 4361,\n",
       " 30,\n",
       " 1,\n",
       " 110,\n",
       " 9186,\n",
       " 1,\n",
       " 699,\n",
       " 2,\n",
       " 2523,\n",
       " 222,\n",
       " 3,\n",
       " 1,\n",
       " 813,\n",
       " 322,\n",
       " 16,\n",
       " 4149,\n",
       " 3,\n",
       " 40,\n",
       " 1223,\n",
       " 4,\n",
       " 16,\n",
       " 4677,\n",
       " 37,\n",
       " 164,\n",
       " 572,\n",
       " 24,\n",
       " 1,\n",
       " 429,\n",
       " 2444,\n",
       " 1956,\n",
       " 4,\n",
       " 3024,\n",
       " 16,\n",
       " 1,\n",
       " 1335,\n",
       " 7,\n",
       " 52,\n",
       " 73,\n",
       " 786,\n",
       " 20,\n",
       " 22350,\n",
       " 3,\n",
       " 1,\n",
       " 120,\n",
       " 699,\n",
       " 2,\n",
       " 1,\n",
       " 75,\n",
       " 8,\n",
       " 5,\n",
       " 88,\n",
       " 2777,\n",
       " 6,\n",
       " 566,\n",
       " 9,\n",
       " 1,\n",
       " 304,\n",
       " 2372,\n",
       " 2,\n",
       " 1238,\n",
       " 1,\n",
       " 126,\n",
       " 295,\n",
       " 15,\n",
       " 16,\n",
       " 17,\n",
       " 183,\n",
       " 418,\n",
       " 9,\n",
       " 40,\n",
       " 5112,\n",
       " 222,\n",
       " 16,\n",
       " 27,\n",
       " 112,\n",
       " 24,\n",
       " 414,\n",
       " 467,\n",
       " 172,\n",
       " 7913,\n",
       " 3,\n",
       " 1,\n",
       " 13960,\n",
       " 234,\n",
       " 2,\n",
       " 145,\n",
       " 211,\n",
       " 5,\n",
       " 20,\n",
       " 841,\n",
       " 31,\n",
       " 1,\n",
       " 5220,\n",
       " 474,\n",
       " 22,\n",
       " 1477,\n",
       " 1,\n",
       " 1426,\n",
       " 2,\n",
       " 8456,\n",
       " 11709,\n",
       " 1,\n",
       " 183,\n",
       " 1659,\n",
       " 9,\n",
       " 1,\n",
       " 519,\n",
       " 2,\n",
       " 6,\n",
       " 2172,\n",
       " 4,\n",
       " 4633,\n",
       " 415,\n",
       " 54,\n",
       " 1138,\n",
       " 3303,\n",
       " 18,\n",
       " 17366,\n",
       " 3,\n",
       " 1,\n",
       " 813,\n",
       " 18,\n",
       " 145,\n",
       " 65,\n",
       " 10,\n",
       " 142,\n",
       " 9,\n",
       " 1,\n",
       " 3219,\n",
       " 519,\n",
       " 2,\n",
       " 1,\n",
       " 110,\n",
       " 4,\n",
       " 977,\n",
       " 5,\n",
       " 40,\n",
       " 589,\n",
       " 82,\n",
       " 1283,\n",
       " 1,\n",
       " 467,\n",
       " 2,\n",
       " 1,\n",
       " 183,\n",
       " 18,\n",
       " 3,\n",
       " 1,\n",
       " 334,\n",
       " 2,\n",
       " 1,\n",
       " 813,\n",
       " 172,\n",
       " 5767,\n",
       " 9340,\n",
       " 1,\n",
       " 1498,\n",
       " 2,\n",
       " 1552,\n",
       " 5374,\n",
       " 358,\n",
       " 7,\n",
       " 91,\n",
       " 4,\n",
       " 1,\n",
       " 110,\n",
       " 322,\n",
       " 30,\n",
       " 262,\n",
       " 5892,\n",
       " 2,\n",
       " 1,\n",
       " 167,\n",
       " 20,\n",
       " 11,\n",
       " 65,\n",
       " 21,\n",
       " 10,\n",
       " 159,\n",
       " 1,\n",
       " 2999,\n",
       " 100,\n",
       " 2,\n",
       " 1552,\n",
       " 3,\n",
       " 270,\n",
       " 30,\n",
       " 6,\n",
       " 3399,\n",
       " 441,\n",
       " 383,\n",
       " 2,\n",
       " 319,\n",
       " 1,\n",
       " 2357,\n",
       " 2,\n",
       " 58,\n",
       " 6,\n",
       " 5313,\n",
       " 6573,\n",
       " 6,\n",
       " 97,\n",
       " 1027,\n",
       " 2107,\n",
       " 9,\n",
       " 1,\n",
       " 167,\n",
       " 2,\n",
       " 12,\n",
       " 62,\n",
       " 1,\n",
       " 112,\n",
       " 2,\n",
       " 1,\n",
       " 627,\n",
       " 734,\n",
       " 2,\n",
       " 283,\n",
       " 105,\n",
       " 23,\n",
       " 16,\n",
       " 40,\n",
       " 196,\n",
       " 10,\n",
       " 435,\n",
       " 96,\n",
       " 647,\n",
       " 980,\n",
       " 19,\n",
       " 12,\n",
       " 1712,\n",
       " 34,\n",
       " 1,\n",
       " 1060,\n",
       " 2,\n",
       " 60,\n",
       " 74,\n",
       " 211,\n",
       " 3,\n",
       " 1,\n",
       " 41,\n",
       " 34,\n",
       " 8,\n",
       " 7,\n",
       " 2,\n",
       " 6,\n",
       " 974,\n",
       " 769,\n",
       " 30,\n",
       " 20,\n",
       " 1,\n",
       " 169,\n",
       " 2,\n",
       " 695,\n",
       " 1005,\n",
       " 25,\n",
       " 1919,\n",
       " 1940,\n",
       " 3552,\n",
       " 67,\n",
       " 16,\n",
       " 16146,\n",
       " 1,\n",
       " 1625,\n",
       " 1,\n",
       " 1156,\n",
       " 10358,\n",
       " 3225,\n",
       " 2,\n",
       " 70,\n",
       " 4,\n",
       " 872,\n",
       " 3005,\n",
       " 5295,\n",
       " 4,\n",
       " 12,\n",
       " 465,\n",
       " 4,\n",
       " 3105,\n",
       " 23,\n",
       " 1216,\n",
       " 61,\n",
       " 1,\n",
       " 1458,\n",
       " 2285,\n",
       " 854,\n",
       " 19,\n",
       " 6,\n",
       " 1393,\n",
       " 837,\n",
       " 2,\n",
       " 20,\n",
       " 35,\n",
       " 23,\n",
       " 3571,\n",
       " 266,\n",
       " 82,\n",
       " 3,\n",
       " 17,\n",
       " 8,\n",
       " 2154,\n",
       " 1,\n",
       " 245,\n",
       " 13960,\n",
       " 234,\n",
       " 114,\n",
       " 1,\n",
       " 1190,\n",
       " 4,\n",
       " 627,\n",
       " 34,\n",
       " 20,\n",
       " 69,\n",
       " 1242,\n",
       " 2349,\n",
       " 134,\n",
       " 11,\n",
       " 8,\n",
       " 2214,\n",
       " 7,\n",
       " 17,\n",
       " 813,\n",
       " 3098,\n",
       " 170,\n",
       " 532,\n",
       " 37,\n",
       " 1080,\n",
       " 196,\n",
       " 2,\n",
       " 3293,\n",
       " 12,\n",
       " 1470,\n",
       " 3,\n",
       " 40,\n",
       " 865,\n",
       " 206,\n",
       " 24,\n",
       " 1,\n",
       " 1583,\n",
       " 58,\n",
       " 6,\n",
       " 563,\n",
       " 13960,\n",
       " 234,\n",
       " 43,\n",
       " 1701,\n",
       " 759,\n",
       " 9,\n",
       " 170,\n",
       " 1,\n",
       " 5509,\n",
       " 465,\n",
       " 2,\n",
       " 145,\n",
       " 16344,\n",
       " 20,\n",
       " 57,\n",
       " 2274,\n",
       " 4090,\n",
       " ...]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequences[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 44669 unique tokens.\n",
      "('Shape of data tensor:', (981, 33317))\n"
     ]
    }
   ],
   "source": [
    "word_index = tokenizer.word_index\n",
    "print('Found %s unique tokens.' % len(word_index))\n",
    "MAX_SEQUENCE_LENGTH = None\n",
    "data = pad_sequences(sequences, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "\n",
    "# labels = to_categorical(np.asarray(labels))\n",
    "print('Shape of data tensor:', data.shape)\n",
    "# print('Shape of label tensor:', labels.shape)\n",
    "\n",
    "# split the data into a training set and a validation set\n",
    "indices = np.arange(data.shape[0])\n",
    "np.random.shuffle(indices)\n",
    "data = data[indices]\n",
    "# labels = labels[indices]\n",
    "VALIDATION_SPLIT = 0.3\n",
    "nb_validation_samples = int(VALIDATION_SPLIT * data.shape[0])\n",
    "\n",
    "x_train = data[:-nb_validation_samples]\n",
    "# y_train = labels[:-nb_validation_samples]\n",
    "x_val = data[-nb_validation_samples:]\n",
    "# y_val = labels[-nb_validation_samples:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 400000 word vectors.\n"
     ]
    }
   ],
   "source": [
    "embeddings_index = {}\n",
    "GLOVE_DIR = './glove.6B/'\n",
    "f = open(os.path.join(GLOVE_DIR, 'glove.6B.100d.txt'))\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:], dtype='float32')\n",
    "    embeddings_index[word] = coefs\n",
    "f.close()\n",
    "\n",
    "print('Found %s word vectors.' % len(embeddings_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "EMBEDDING_DIM = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "embedding_matrix = np.zeros((len(word_index) + 1, EMBEDDING_DIM))\n",
    "for word, i in word_index.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        # words not found in embedding index will be all-zeros.\n",
    "        embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.layers import Embedding\n",
    "\n",
    "embedding_layer = Embedding(len(word_index) + 1,\n",
    "                            EMBEDDING_DIM,\n",
    "                            weights=[embedding_matrix],\n",
    "                            input_length=MAX_SEQUENCE_LENGTH,\n",
    "                            trainable=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# #TODO\n",
    "\n",
    "# 1. Pad sentences to length 100 words. - D\n",
    "# 2. Pad docs to length 400 sents. - D\n",
    "# 3. Get arr of arr of indices of the words. - D\n",
    "# 4. Pass thru embed layer, get vec of vec for each par.\n",
    "# 5. Add GRU\n",
    "# 6. Add attention.\n",
    "# 7. Take weighted sum.\n",
    "# 8. Add GRU.\n",
    "# 9. Add attention.\n",
    "# 10. Take weighted sum.\n",
    "# 11. Add softmax and train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
