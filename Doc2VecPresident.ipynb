{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import locale\n",
    "import glob,os, random\n",
    "import os.path\n",
    "import requests\n",
    "import tarfile\n",
    "\n",
    "\n",
    "# Convert text to lower-case and strip punctuation/symbols from words\n",
    "def normalize_text(text):\n",
    "    norm_text = text.lower()\n",
    "\n",
    "    # Replace breaks with spaces\n",
    "    norm_text = norm_text.replace('<br />', ' ')\n",
    "\n",
    "    # Pad punctuation with spaces on both sides\n",
    "    for char in ['.', '\"', ',', '(', ')', '!', '?', ';', ':']:\n",
    "        norm_text = norm_text.replace(char, ' ' + char + ' ')\n",
    "\n",
    "    return norm_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index([u'foldername', u'label'], dtype='object') 34\n"
     ]
    }
   ],
   "source": [
    "fields = ['foldername', 'label']\n",
    "\n",
    "\n",
    "df = pd.read_csv('/scratch/qx344/speech_data/presidents_meta.csv', usecols=fields,skipinitialspace=True)\n",
    "# See the keys\n",
    "print df.keys(),len(df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "862 docs: 828 train-sentiment, 34 test-sentiment\n"
     ]
    }
   ],
   "source": [
    "import gensim\n",
    "from gensim.models.doc2vec import TaggedDocument\n",
    "from collections import namedtuple\n",
    "import io\n",
    "\n",
    "SentimentDocument = namedtuple('SentimentDocument', 'words tags split sentiment')\n",
    "\n",
    "alldocs = []  # will hold all docs in original order\n",
    "\n",
    "#for line_no, line in enumerate(alldata):\n",
    "index = 0\n",
    "for line_no, row in df.iterrows():\n",
    "    sentiment = row['label']*1.0\n",
    "    os.chdir(\"/scratch/qx344/speech_data/data/{0}\".format(row['foldername']))\n",
    "    filesNum = len(os.listdir('.'))\n",
    "    testfile = random.choice(os.listdir('.')) \n",
    "    with open(testfile, 'r') as myfile:\n",
    "        line = myfile.read().replace('\\n', '')\n",
    "        words = gensim.utils.to_unicode(line).split()\n",
    "        split ='test' \n",
    "        tags = [index] # `tags = [tokens[0]]` would also work at extra memory cost\n",
    "        index = index + 1\n",
    "        alldocs.append(SentimentDocument(words, tags, split, sentiment))\n",
    "        trainfilelist = glob.glob(\"*.txt\")\n",
    "        trainfilelist.remove(testfile)\n",
    "    for txtfile in trainfilelist:\n",
    "        with open(txtfile, 'r') as myfile:\n",
    "            line = myfile.read().replace('\\n', '')\n",
    "            words = gensim.utils.to_unicode(line).split()\n",
    "            tags = [index] # `tags = [tokens[0]]` would also work at extra memory cost\n",
    "            index = index + 1\n",
    "            split ='train'  \n",
    "            alldocs.append(SentimentDocument(words, tags, split, sentiment))\n",
    "\n",
    "train_docs = [doc for doc in alldocs if doc.split == 'train']\n",
    "test_docs = [doc for doc in alldocs if doc.split == 'test']\n",
    "doc_list = alldocs[:]  # for reshuffling per pass\n",
    "\n",
    "print('%d docs: %d train-sentiment, %d test-sentiment' % (len(doc_list), len(train_docs), len(test_docs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doc2Vec(dm/c,d80,n5,w5,mc2,t20)\n",
      "Doc2Vec(dbow,d80,n5,mc2,t20)\n",
      "Doc2Vec(dm/m,d80,n5,w10,mc2,t20)\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import Doc2Vec\n",
    "import gensim.models.doc2vec\n",
    "from collections import OrderedDict\n",
    "import multiprocessing\n",
    "\n",
    "cores = multiprocessing.cpu_count()\n",
    "assert gensim.models.doc2vec.FAST_VERSION > -1, \"this will be painfully slow otherwise\"\n",
    "\n",
    "simple_models = [\n",
    "    # PV-DM w/concatenation - window=5 (both sides) approximates paper's 10-word total window size\n",
    "    Doc2Vec(dm=1, dm_concat=1, size=80, window=5, negative=5, hs=0, min_count=2, workers=cores),\n",
    "    # PV-DBOW \n",
    "    Doc2Vec(dm=0, size=80, negative=5, hs=0, min_count=2, workers=cores),\n",
    "    # PV-DM w/average\n",
    "    Doc2Vec(dm=1, dm_mean=1, size=80, window=10, negative=5, hs=0, min_count=2, workers=cores),\n",
    "]\n",
    "\n",
    "# speed setup by sharing results of 1st model's vocabulary scan\n",
    "simple_models[0].build_vocab(alldocs)  # PV-DM/concat requires one special NULL word so it serves as template\n",
    "print(simple_models[0])\n",
    "for model in simple_models[1:]:\n",
    "    model.reset_from(simple_models[0])\n",
    "    print(model)\n",
    "\n",
    "models_by_name = OrderedDict((str(model), model) for model in simple_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from gensim.test.test_doc2vec import ConcatenatedDoc2Vec\n",
    "models_by_name['dbow+dmm'] = ConcatenatedDoc2Vec([simple_models[1], simple_models[2]])\n",
    "models_by_name['dbow+dmc'] = ConcatenatedDoc2Vec([simple_models[1], simple_models[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "from random import sample\n",
    "\n",
    "# for timing\n",
    "from contextlib import contextmanager\n",
    "from timeit import default_timer\n",
    "import time \n",
    "\n",
    "@contextmanager\n",
    "def elapsed_timer():\n",
    "    start = default_timer()\n",
    "    elapser = lambda: default_timer() - start\n",
    "    yield lambda: elapser()\n",
    "    end = default_timer()\n",
    "    elapser = lambda: end-start\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "from sklearn import linear_model\n",
    "\n",
    "\n",
    "def error_rate_for_model(test_model, train_set, test_set, infer=False, infer_steps=3, infer_alpha=0.1, infer_subsample=0.1):\n",
    "    \"\"\"Report error rate on test_doc sentiments, using supplied model and train_docs\"\"\"\n",
    "\n",
    "    train_targets, train_regressors = zip(*[(doc.sentiment, test_model.docvecs[doc.tags[0]]) for doc in train_set])\n",
    "    #train_regressors = sm.add_constant(train_regressors)\n",
    "    logit = linear_model.LogisticRegression(penalty='l2', dual=False, tol=0.0001, C=1.0, fit_intercept=True, \n",
    "                                        intercept_scaling=1, class_weight=None, random_state=None, solver='lbfgs', max_iter=300, \n",
    "                                        multi_class='multinomial', verbose=0, warm_start=False, n_jobs=1)\n",
    "    predictor = logit.fit(train_regressors,train_targets)\n",
    "\n",
    "    test_targets, test_regressors = zip(*[(doc.sentiment, test_model.docvecs[doc.tags[0]]) for doc in test_set])\n",
    "    \n",
    "    corrects = predictor.score(test_regressors,test_targets)\n",
    "    error_rate= 1 - corrects\n",
    "    errors = len(test_targets)*error_rate\n",
    "    return (error_rate, errors, len(test_targets), predictor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "best_error = defaultdict(lambda :1.0)  # to selectively-print only best errors achieved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "START 2016-12-04 21:21:46.252534\n",
      "*0.529412 : 1 passes : Doc2Vec(dm/c,d80,n5,w5,mc2,t20) 19.6s 0.1s\n",
      "*0.294118 : 1 passes : Doc2Vec(dbow,d80,n5,mc2,t20) 6.0s 0.1s\n",
      "*0.558824 : 1 passes : Doc2Vec(dm/m,d80,n5,w10,mc2,t20) 10.7s 0.2s\n",
      "*0.352941 : 1 passes : dbow+dmm 0.0s 0.2s\n",
      "*0.382353 : 1 passes : dbow+dmc 0.0s 0.2s\n",
      "completed pass 1 at alpha 0.025000\n",
      "*0.441176 : 2 passes : Doc2Vec(dm/c,d80,n5,w5,mc2,t20) 17.1s 0.1s\n",
      "*0.294118 : 2 passes : Doc2Vec(dbow,d80,n5,mc2,t20) 6.0s 0.1s\n",
      "*0.352941 : 2 passes : Doc2Vec(dm/m,d80,n5,w10,mc2,t20) 10.7s 0.2s\n",
      " 0.382353 : 2 passes : dbow+dmm 0.0s 0.2s\n",
      "*0.294118 : 2 passes : dbow+dmc 0.0s 0.2s\n",
      "completed pass 2 at alpha 0.023800\n",
      " 0.529412 : 3 passes : Doc2Vec(dm/c,d80,n5,w5,mc2,t20) 16.2s 0.1s\n",
      " 0.411765 : 3 passes : Doc2Vec(dbow,d80,n5,mc2,t20) 6.0s 0.1s\n",
      " 0.382353 : 3 passes : Doc2Vec(dm/m,d80,n5,w10,mc2,t20) 10.5s 0.2s\n",
      " 0.382353 : 3 passes : dbow+dmm 0.0s 0.2s\n",
      " 0.323529 : 3 passes : dbow+dmc 0.0s 0.2s\n",
      "completed pass 3 at alpha 0.022600\n",
      "*0.441176 : 4 passes : Doc2Vec(dm/c,d80,n5,w5,mc2,t20) 15.7s 0.1s\n",
      " 0.411765 : 4 passes : Doc2Vec(dbow,d80,n5,mc2,t20) 5.9s 0.1s\n",
      " 0.382353 : 4 passes : Doc2Vec(dm/m,d80,n5,w10,mc2,t20) 10.5s 0.2s\n",
      " 0.382353 : 4 passes : dbow+dmm 0.0s 0.2s\n",
      "*0.264706 : 4 passes : dbow+dmc 0.0s 0.2s\n",
      "completed pass 4 at alpha 0.021400\n",
      " 0.558824 : 5 passes : Doc2Vec(dm/c,d80,n5,w5,mc2,t20) 15.4s 0.2s\n",
      " 0.323529 : 5 passes : Doc2Vec(dbow,d80,n5,mc2,t20) 5.8s 0.1s\n",
      " 0.411765 : 5 passes : Doc2Vec(dm/m,d80,n5,w10,mc2,t20) 10.4s 0.2s\n",
      "*0.323529 : 5 passes : dbow+dmm 0.0s 0.2s\n",
      " 0.352941 : 5 passes : dbow+dmc 0.0s 0.2s\n",
      "completed pass 5 at alpha 0.020200\n",
      " 0.500000 : 6 passes : Doc2Vec(dm/c,d80,n5,w5,mc2,t20) 15.2s 0.2s\n",
      " 0.352941 : 6 passes : Doc2Vec(dbow,d80,n5,mc2,t20) 6.0s 0.1s\n",
      " 0.382353 : 6 passes : Doc2Vec(dm/m,d80,n5,w10,mc2,t20) 10.4s 0.2s\n",
      "*0.294118 : 6 passes : dbow+dmm 0.0s 0.2s\n",
      "*0.264706 : 6 passes : dbow+dmc 0.0s 0.2s\n",
      "completed pass 6 at alpha 0.019000\n",
      "*0.411765 : 7 passes : Doc2Vec(dm/c,d80,n5,w5,mc2,t20) 15.1s 0.2s\n",
      " 0.323529 : 7 passes : Doc2Vec(dbow,d80,n5,mc2,t20) 5.9s 0.2s\n",
      " 0.382353 : 7 passes : Doc2Vec(dm/m,d80,n5,w10,mc2,t20) 10.7s 0.2s\n",
      "*0.294118 : 7 passes : dbow+dmm 0.0s 0.2s\n",
      "*0.264706 : 7 passes : dbow+dmc 0.0s 0.2s\n",
      "completed pass 7 at alpha 0.017800\n",
      " 0.470588 : 8 passes : Doc2Vec(dm/c,d80,n5,w5,mc2,t20) 15.1s 0.2s\n",
      "*0.294118 : 8 passes : Doc2Vec(dbow,d80,n5,mc2,t20) 6.0s 0.1s\n",
      " 0.382353 : 8 passes : Doc2Vec(dm/m,d80,n5,w10,mc2,t20) 10.4s 0.2s\n",
      " 0.323529 : 8 passes : dbow+dmm 0.0s 0.2s\n",
      "*0.264706 : 8 passes : dbow+dmc 0.0s 0.2s\n",
      "completed pass 8 at alpha 0.016600\n",
      " 0.441176 : 9 passes : Doc2Vec(dm/c,d80,n5,w5,mc2,t20) 15.0s 0.2s\n",
      "*0.264706 : 9 passes : Doc2Vec(dbow,d80,n5,mc2,t20) 5.9s 0.1s\n",
      " 0.382353 : 9 passes : Doc2Vec(dm/m,d80,n5,w10,mc2,t20) 10.4s 0.2s\n",
      " 0.323529 : 9 passes : dbow+dmm 0.0s 0.2s\n",
      " 0.294118 : 9 passes : dbow+dmc 0.0s 0.2s\n",
      "completed pass 9 at alpha 0.015400\n",
      " 0.500000 : 10 passes : Doc2Vec(dm/c,d80,n5,w5,mc2,t20) 15.0s 0.2s\n",
      " 0.323529 : 10 passes : Doc2Vec(dbow,d80,n5,mc2,t20) 5.9s 0.1s\n",
      " 0.411765 : 10 passes : Doc2Vec(dm/m,d80,n5,w10,mc2,t20) 10.4s 0.2s\n",
      " 0.323529 : 10 passes : dbow+dmm 0.0s 0.2s\n",
      "*0.264706 : 10 passes : dbow+dmc 0.0s 0.2s\n",
      "completed pass 10 at alpha 0.014200\n",
      " 0.470588 : 11 passes : Doc2Vec(dm/c,d80,n5,w5,mc2,t20) 15.0s 0.2s\n",
      " 0.294118 : 11 passes : Doc2Vec(dbow,d80,n5,mc2,t20) 6.0s 0.1s\n",
      " 0.411765 : 11 passes : Doc2Vec(dm/m,d80,n5,w10,mc2,t20) 10.5s 0.2s\n",
      "*0.294118 : 11 passes : dbow+dmm 0.0s 0.2s\n",
      " 0.323529 : 11 passes : dbow+dmc 0.0s 0.2s\n",
      "completed pass 11 at alpha 0.013000\n",
      "*0.411765 : 12 passes : Doc2Vec(dm/c,d80,n5,w5,mc2,t20) 15.1s 0.2s\n",
      " 0.294118 : 12 passes : Doc2Vec(dbow,d80,n5,mc2,t20) 5.9s 0.1s\n",
      " 0.441176 : 12 passes : Doc2Vec(dm/m,d80,n5,w10,mc2,t20) 10.4s 0.2s\n",
      "*0.235294 : 12 passes : dbow+dmm 0.0s 0.2s\n",
      " 0.323529 : 12 passes : dbow+dmc 0.0s 0.2s\n",
      "completed pass 12 at alpha 0.011800\n",
      " 0.500000 : 13 passes : Doc2Vec(dm/c,d80,n5,w5,mc2,t20) 15.0s 0.2s\n",
      " 0.352941 : 13 passes : Doc2Vec(dbow,d80,n5,mc2,t20) 5.9s 0.1s\n",
      " 0.411765 : 13 passes : Doc2Vec(dm/m,d80,n5,w10,mc2,t20) 10.6s 0.2s\n",
      " 0.294118 : 13 passes : dbow+dmm 0.0s 0.4s\n",
      "*0.264706 : 13 passes : dbow+dmc 0.0s 0.2s\n",
      "completed pass 13 at alpha 0.010600\n",
      " 0.500000 : 14 passes : Doc2Vec(dm/c,d80,n5,w5,mc2,t20) 14.9s 0.2s\n",
      " 0.323529 : 14 passes : Doc2Vec(dbow,d80,n5,mc2,t20) 5.8s 0.1s\n",
      " 0.382353 : 14 passes : Doc2Vec(dm/m,d80,n5,w10,mc2,t20) 10.5s 0.2s\n",
      "*0.235294 : 14 passes : dbow+dmm 0.0s 0.2s\n",
      "*0.235294 : 14 passes : dbow+dmc 0.0s 0.2s\n",
      "completed pass 14 at alpha 0.009400\n",
      "*0.411765 : 15 passes : Doc2Vec(dm/c,d80,n5,w5,mc2,t20) 14.9s 0.2s\n",
      " 0.323529 : 15 passes : Doc2Vec(dbow,d80,n5,mc2,t20) 5.9s 0.1s\n",
      "*0.352941 : 15 passes : Doc2Vec(dm/m,d80,n5,w10,mc2,t20) 10.5s 0.2s\n",
      "*0.235294 : 15 passes : dbow+dmm 0.0s 0.2s\n",
      " 0.323529 : 15 passes : dbow+dmc 0.0s 0.2s\n",
      "completed pass 15 at alpha 0.008200\n",
      " 0.500000 : 16 passes : Doc2Vec(dm/c,d80,n5,w5,mc2,t20) 14.9s 0.2s\n",
      " 0.294118 : 16 passes : Doc2Vec(dbow,d80,n5,mc2,t20) 5.9s 0.1s\n",
      " 0.382353 : 16 passes : Doc2Vec(dm/m,d80,n5,w10,mc2,t20) 10.4s 0.2s\n",
      "*0.235294 : 16 passes : dbow+dmm 0.0s 0.2s\n",
      " 0.294118 : 16 passes : dbow+dmc 0.0s 0.2s\n",
      "completed pass 16 at alpha 0.007000\n",
      " 0.500000 : 17 passes : Doc2Vec(dm/c,d80,n5,w5,mc2,t20) 15.0s 0.2s\n",
      " 0.352941 : 17 passes : Doc2Vec(dbow,d80,n5,mc2,t20) 5.9s 0.1s\n",
      " 0.382353 : 17 passes : Doc2Vec(dm/m,d80,n5,w10,mc2,t20) 10.4s 0.2s\n",
      "*0.235294 : 17 passes : dbow+dmm 0.0s 0.2s\n",
      " 0.294118 : 17 passes : dbow+dmc 0.0s 0.2s\n",
      "completed pass 17 at alpha 0.005800\n",
      " 0.500000 : 18 passes : Doc2Vec(dm/c,d80,n5,w5,mc2,t20) 14.9s 0.2s\n",
      " 0.294118 : 18 passes : Doc2Vec(dbow,d80,n5,mc2,t20) 5.8s 0.1s\n",
      " 0.382353 : 18 passes : Doc2Vec(dm/m,d80,n5,w10,mc2,t20) 10.5s 0.2s\n",
      "*0.235294 : 18 passes : dbow+dmm 0.0s 0.2s\n",
      " 0.294118 : 18 passes : dbow+dmc 0.0s 0.2s\n",
      "completed pass 18 at alpha 0.004600\n",
      " 0.529412 : 19 passes : Doc2Vec(dm/c,d80,n5,w5,mc2,t20) 14.9s 0.2s\n",
      " 0.294118 : 19 passes : Doc2Vec(dbow,d80,n5,mc2,t20) 5.9s 0.1s\n",
      "*0.294118 : 19 passes : Doc2Vec(dm/m,d80,n5,w10,mc2,t20) 10.5s 0.2s\n",
      "*0.235294 : 19 passes : dbow+dmm 0.0s 0.2s\n",
      " 0.264706 : 19 passes : dbow+dmc 0.0s 0.2s\n",
      "completed pass 19 at alpha 0.003400\n",
      " 0.500000 : 20 passes : Doc2Vec(dm/c,d80,n5,w5,mc2,t20) 15.0s 0.2s\n",
      "*0.264706 : 20 passes : Doc2Vec(dbow,d80,n5,mc2,t20) 5.8s 0.1s\n",
      " 0.352941 : 20 passes : Doc2Vec(dm/m,d80,n5,w10,mc2,t20) 10.4s 0.2s\n",
      "*0.235294 : 20 passes : dbow+dmm 0.0s 0.2s\n",
      " 0.294118 : 20 passes : dbow+dmc 0.0s 0.2s\n",
      "completed pass 20 at alpha 0.002200\n",
      "END 2016-12-04 21:32:41.818063\n"
     ]
    }
   ],
   "source": [
    "from random import shuffle\n",
    "import datetime\n",
    "\n",
    "alpha, min_alpha, passes = (0.025, 0.001, 20)\n",
    "alpha_delta = (alpha - min_alpha) / passes\n",
    "\n",
    "print(\"START %s\" % datetime.datetime.now())\n",
    "\n",
    "for epoch in range(passes):\n",
    "    shuffle(doc_list)  # shuffling gets best results\n",
    "    \n",
    "    for name, train_model in models_by_name.items():\n",
    "        # train\n",
    "        duration = 'na'\n",
    "        train_model.alpha, train_model.min_alpha = alpha, alpha\n",
    "        with elapsed_timer() as elapsed:\n",
    "            train_model.train(doc_list)\n",
    "            duration = '%.1f' % elapsed()\n",
    "            \n",
    "        # evaluate\n",
    "        eval_duration = ''\n",
    "        with elapsed_timer() as eval_elapsed:\n",
    "            err, err_count, test_count, predictor = error_rate_for_model(train_model, train_docs, test_docs)\n",
    "        eval_duration = '%.1f' % eval_elapsed()\n",
    "        best_indicator = ' '\n",
    "        if err <= best_error[name]:\n",
    "            best_error[name] = err\n",
    "            best_indicator = '*' \n",
    "        print(\"%s%f : %i passes : %s %ss %ss\" % (best_indicator, err, epoch + 1, name, duration, eval_duration))\n",
    "\n",
    "#         if ((epoch + 1) % 5) == 0 or epoch == 0:\n",
    "#             eval_duration = ''\n",
    "#             with elapsed_timer() as eval_elapsed:\n",
    "#                 infer_err, err_count, test_count, predictor = error_rate_for_model(train_model, train_docs, test_docs, infer=True)\n",
    "#             eval_duration = '%.1f' % eval_elapsed()\n",
    "#             best_indicator = ' '\n",
    "#             if infer_err < best_error[name + '_inferred']:\n",
    "#                 best_error[name + '_inferred'] = infer_err\n",
    "#                 best_indicator = '*'\n",
    "#             print(\"%s%f : %i passes : %s %ss %ss\" % (best_indicator, infer_err, epoch + 1, name + '_inferred', duration, eval_duration))\n",
    "\n",
    "    print('completed pass %i at alpha %f' % (epoch + 1, alpha))\n",
    "    alpha -= alpha_delta\n",
    "    \n",
    "print(\"END %s\" % str(datetime.datetime.now()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##### please omit anything below ############"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##### please omit anything below ############"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##### please omit anything below ############"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from random import shuffle\n",
    "import datetime\n",
    "\n",
    "alpha, min_alpha, passes = (0.025, 0.001, 20)\n",
    "alpha_delta = (alpha - min_alpha) / passes\n",
    "\n",
    "\n",
    "shuffle(doc_list)  # shuffling gets best results\n",
    "\n",
    "limiter = 1\n",
    "for name, train_model in models_by_name.items():\n",
    "    # train\n",
    "    train_model.alpha, train_model.min_alpha = alpha, alpha\n",
    "    train_model.train(doc_list)\n",
    "    if limiter>0:\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "err, err_count, test_count, predictor = error_rate_for_model(train_model, train_docs, test_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_targets, train_regressors = zip(*[(doc.sentiment, train_model.docvecs[doc.tags[0]]) for doc in train_docs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_targets, test_regressors = zip(*[(doc.sentiment, train_model.docvecs[doc.tags[0]]) for doc in test_docs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "\n",
    "classfier1 =linear_model.LogisticRegression(penalty='l2', dual=False, tol=0.0001, C=1.0, fit_intercept=True, \n",
    "                                        intercept_scaling=1, class_weight=None, random_state=None, solver='lbfgs', max_iter=300, \n",
    "                                        multi_class='multinomial', verbose=0, warm_start=False, n_jobs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=300, multi_class='multinomial',\n",
       "          n_jobs=1, penalty='l2', random_state=None, solver='lbfgs',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classfier1.fit(train_regressors,train_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.43021999999999999"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classfier1.score(test_regressors,test_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "classfier2 =  OneVsRestClassifier(LinearSVC(random_state=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OneVsRestClassifier(estimator=LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
       "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "     multi_class='ovr', penalty='l2', random_state=0, tol=0.0001,\n",
       "     verbose=0),\n",
       "          n_jobs=1)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classfier2.fit(train_regressors,train_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.43181999999999998"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classfier2.score(test_regressors,test_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape=None, degree=3, gamma='auto', kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "classfier3 = svm.SVC()\n",
    "classfier3.fit(train_regressors,train_targets) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.313"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classfier3.score(test_regressors,test_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "logit = sm.Logit(train_targets, train_regressors)\n",
    "\n",
    "error_rate_for_model(test_model, train_set, test_set, infer=False, infer_steps=3, infer_alpha=0.1, infer_subsample=0.1)\n",
    "    \n",
    "error_rate_for_model(train_model, train_docs, test_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_targets, train_regressors = zip(*[(doc.sentiment, train_model.docvecs[doc.tags[0]]) for doc in train_docs])\n",
    "    train_regressors = sm.add_constant(train_regressors)\n",
    "    predictor = logistic_predictor_from_data(train_targets, train_regressors)\n",
    "\n",
    "    #test_data = test_set\n",
    "    test_data = test_set  ### for test\n",
    "    if infer:\n",
    "        if infer_subsample < 1.0:\n",
    "            test_data = sample(test_data, int(infer_subsample * len(test_data)))\n",
    "        test_regressors = [test_model.infer_vector(doc.words, steps=infer_steps, alpha=infer_alpha) for doc in test_data]\n",
    "    else:\n",
    "        #print test_docs[:3]  ##  for test\n",
    "        test_regressors = [test_model.docvecs[doc.tags[0]] for doc in test_docs]\n",
    "    test_regressors = sm.add_constant(test_regressors)\n",
    "    \n",
    "    # predict & evaluate\n",
    "    Rawtest_predictions = predictor.predict(test_regressors)\n",
    "    \n",
    "    #print test_predictions ## for test\n",
    "    test_predictions = Rawtest_predictions #[ np.argmax(RL) for RL in Rawtest_predictions] ## for test\n",
    "    #print test_predictions ## for test\n",
    "    \n",
    "    corrects = sum(np.rint(test_predictions) == [doc.sentiment for doc in test_data])\n",
    "    errors = len(test_predictions) - corrects\n",
    "    error_rate = float(errors) / len(test_predictions)\n",
    "    return (error_rate, errors, len(test_predictions), predictor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import glob, os\n",
    "os.chdir(\"/scratch/qx344/speech_data/data/{0}\".format(df['foldername'][0]))\n",
    "for file in glob.glob(\"*.txt\"):\n",
    "    print(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print df['foldername'][0]\n",
    "os.chdir(\"/scratch/qx344/speech_data/data/{0}\".format(df['foldername'][0]))\n",
    "len(os.listdir('.')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('/scratch/qx344/speech_data/data/adams/combined.txt', 'r') as myfile:\n",
    "    data=myfile.read().replace('\\n', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22 docs: 21 train-sentiment, 1 test-sentiment\n"
     ]
    }
   ],
   "source": [
    "### this is picking last file as text file\n",
    "import gensim\n",
    "from gensim.models.doc2vec import TaggedDocument\n",
    "from collections import namedtuple\n",
    "import io\n",
    "\n",
    "SentimentDocument = namedtuple('SentimentDocument', 'words tags split sentiment')\n",
    "\n",
    "alldocs = []  # will hold all docs in original order\n",
    "\n",
    "#for line_no, line in enumerate(alldata):\n",
    "index = 0\n",
    "for line_no, row in df.iterrows():\n",
    "    sentiment = row['label']*1.0\n",
    "    os.chdir(\"/scratch/qx344/speech_data/data/{0}\".format(row['foldername']))\n",
    "    filesNum = len(os.listdir('.'))\n",
    "    localindex = 1\n",
    "    for txtfile in glob.glob(\"*.txt\"):\n",
    "        with open(txtfile, 'r') as myfile:\n",
    "            line = myfile.read().replace('\\n', '')\n",
    "            words = gensim.utils.to_unicode(line).split()\n",
    "            tags = [index] # `tags = [tokens[0]]` would also work at extra memory cost\n",
    "            index = index + 1\n",
    "            split ='train' if localindex<filesNum else 'test' #['train','train','train','test'][line_no//25000]  # 75k train, 25k test\n",
    "            localindex = localindex+1\n",
    "            alldocs.append(SentimentDocument(words, tags, split, sentiment))\n",
    "\n",
    "train_docs = [doc for doc in alldocs if doc.split == 'train']\n",
    "test_docs = [doc for doc in alldocs if doc.split == 'test']\n",
    "doc_list = alldocs[:]  # for reshuffling per pass\n",
    "\n",
    "print('%d docs: %d train-sentiment, %d test-sentiment' % (len(doc_list), len(train_docs), len(test_docs)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
