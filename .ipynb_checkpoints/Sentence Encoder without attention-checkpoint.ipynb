{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/shivamverma/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "from keras.layers import Input, Dense\n",
    "import chainer\n",
    "from chainer import Function, gradient_check, report, training, utils, Variable\n",
    "from chainer import datasets, iterators, optimizers, serializers\n",
    "from chainer import Link, Chain, ChainList\n",
    "import chainer.functions as F\n",
    "import chainer.links as L\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.layers import Dense, Input, Flatten, LSTM, Reshape, Lambda\n",
    "from keras.layers import Conv1D, MaxPooling1D, Embedding\n",
    "from keras.models import Model, Sequential\n",
    "from chainer.training import extensions\n",
    "import os, sys, re\n",
    "from nltk import tokenize\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "import string \n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.7.9 (v2.7.9:648dcafa7e5f, Dec 10 2014, 10:10:46) \n",
      "[GCC 4.2.1 (Apple Inc. build 5666) (dot 3)]\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TEXT_DATA_DIR = './speech_data/data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load the labels \n",
    "df = pd.read_csv('./speech_data/presidents_meta.csv')\n",
    "label_dict = dict(zip(list(df.foldername), list(df.label)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_dict['arthur']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 862 texts.\n",
      "Found 862 texts.\n"
     ]
    }
   ],
   "source": [
    "texts = []  # list of text samples\n",
    "# labels_index = {}  # dictionary mapping label name to numeric id\n",
    "labels = []  # list of label ids\n",
    "\n",
    "\n",
    "for name in sorted(os.listdir(TEXT_DATA_DIR)):\n",
    "\n",
    "    path = os.path.join(TEXT_DATA_DIR, name)\n",
    "    if os.path.isdir(path):\n",
    "        for fname in sorted(os.listdir(path)):\n",
    "            if 'combined' not in fname and 'combines' not in fname:\n",
    "                president_name = path.split('/')[-1]\n",
    "                fpath = os.path.join(path, fname)\n",
    "                f = open(fpath)\n",
    "                if (president_name in label_dict):\n",
    "                    labels.append(label_dict[president_name])\n",
    "                    line = f.read()\n",
    "                    line = re.sub(r'[^\\x00-\\x7F]+',' ', line).lower()\n",
    "                    texts.append(line)\n",
    "                f.close()\n",
    "                \n",
    "\n",
    "print('Found %s texts.' % len(texts))\n",
    "print('Found %s texts.' % len(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'the president. good afternoon, ladies and gentlemen.i have been asked to give a statement about the consular convention that is pending before the united states senate.i should like to say very briefly that i hope the senate will give its advice and consent to the proposed convention with the u.s.s.r. i feel very strongly that the ratification of this treaty is very much in our national interest. i feel this way for two principal reasons:first, we need this treaty to protect 18,000 american citizens who each year travel from this country to the soviet the convention requires immediate notification to us whenever an american is arrested in the soviet union. it insures our right to visit that citizen within 4 and as often thereafter as is desirable.we think that we need these rights help to protect american citizens. these are rights which the soviet citizens already have who travel in this country, because guaranteed by our constitution.second, the convention does not require the opening of consulates in this country or in the soviet union. it does provide that should any such consulate be opened, the officials would have diplomatic immunity.the secretary of state informs me that no negotiations for consulates are underway and that the most that he can envision in the foreseeable future is the opening of one consulate in each country, to be manned by from 10 to 15 people.there are presently 452 soviet officials in the united states who have diplomatic immunity. if an additional consulate were opened, and if another 10 were added to the 452, mr. hoover has assured me that this small increment would raise no problems which the fbi cannot effectively and efficiently deal with.in short, i think we very much need this convention to protect american interests, and to protect american citizens abroad. in my judgment, it raises no problem with respect to our national security. therefore, i hope very much that the senate, in its wisdom, after full debate, will see fit to ratify it. i will be glad to have any questions.q. we are hearing and reading and writing a good deal lately about diplomacy aimed at a vietnam settlement. i wonder if you could give us your assessment of the peace front at this time.the president. mr. cormier states a question that i know is on the minds of all the people here today and all the people in this country.as you know, i have underlined over and over again the very deep interest of the united states in a prompt and peaceful settlement of all the problems in southeast asia.i have said many times that we are ready to go more than halfway in achieving this result.i would remind all of you that we would welcome a conference in southeast asia. this might be a geneva conference. it could be an all-asian conference, or any other generally acceptable forum.we would be glad to see the unconditional discussions to which i referred in my statement of april 1965 at johns hopkins.we would participate in preliminary discussions which might open the way for formal negotiations.we are prepared today to talk about mutual steps of deescalation.we would be prepared to talk about such subjects as the exchange of prisoners, the demilitarization, or the demilitarized zone, or any other aspect which might take even a small step in the direction of peace.we would be prepared to discuss any points which the other side wishes to bring up, along with points which we and our allies very much want to raise ourselves.or there could be preliminary discussions to see whether there could be an agreed set of points which could be the basis for negotiation.so it is against this background that we study very carefully all of the public statements made which appear from time to time and which bear upon southeast asia, and all the views which we receive from or through other governments.it would not be helpful to me--and i do not intend to do so--to comment on any particular channel or communications at this point. but you may be sure that we are diligent in our search for the possibility of peaceful settlement.in all candor, i must say that i am not aware of any serious effort that the other side has made, in my judgment, to bring the fighting to a stop and to stop the war.q. mr. president, you have been so eloquent in the past about expressing your desire for peaceful negotiations. i would like to ask you whether or not--if you thought it would speed this war down the road to peace--you would be willing personally to participate in negotiations with some of your opposite numbers, such as the leadership in hanoi?the president. we have made clear that if the other side desires to discuss peace at any time, we will be very happy to have appropriate arrangements made to see that that is carried out.where we would talk, who would talk, what we would talk about are all matters that could be worked out between the two governments involved.we have made clear to them, and to the world, the principles that we believe must govern a peace meeting of this kind, and a settlement that we would hope would come out of it: the honoring of the geneva accords of 1954 and 1962, the right of self-determination for the people of south vietnam, to insure that they are freed from the threat or use of force.but we have, i must say, as of today no indication that the other side is prepared in any way to settle on these limited and decent terms.we hope very much that we can have some signals in that direction, but i in candor must say that as of now we do not have.q. mr. president, does your expressed willingness to negotiate a peaceful settlement imply any willingness to compromise on any of our stated objectives in that part of the world?the president. i think that any peace agreement will involve understandings on both parts and certain concessions on both parts and certain understandings. i don\\'t think that we can determine those before we come together, or through any press conference techniques.i can only repeat what i said in the state of the union: that i wish that the conflict in vietnam was over.and i can only repeat what i have said: so many times: i will do anything i can the part of this government to go more than halfway to bring it to an end.i must say that we face great costs. we face agony. we do plan to carry out our efforts out there. we are going to support our troops in the field. we are going to work with our vietnamese allies toward pacification and constitutional government.while we are doing that, every hour of every day the spokesmen for this government are under instructions to explore every possibility for peace.but i do not want to disillusion any of you. and i do not want any of you to be caught by speculation. as of this moment, i cannot report that there are any serious indications that the other side is ready to stop the war.q. you have three times now used phrase \"no serious efforts by the other to bring the war to a close.\"how would you characterize what has been going on in the last couple of weeks? do you recognize any signs of maneuverability or fluidity in their position?the president. i see almost every day some speculation by some individual or some hope or desire expressed by some government. and i assume that different individuals get different impressions. certainly they have different hopes. i can only \"speak for myself, john,\" and with the information that i have, with the knowledge that is brought to me, i must say that i do not interpret any action that i have observed as being a serious effort to either go to a conference table or to bring the war to an end.q. mr. president, could you give us your assessment of how recent events in china may be affecting the chances for peace in vietnam?first of all, your assessment of what is happening in china, and then how you think that may affect the chance of a peace?the president. i think that there is little i can add to what the general public knows about the events in china. i think that we all know that they are having very serious problems.and i would not think that would add anything to the strength of our adversaries in that area. i think that we can see from some of the problems that we have ourselves from time to time that unity is very important in connection with our operations.and i do not see that the differences in china are going to contribute anything to the strength of the north vietnamese.on the other hand, i do not want to hold out any hopes to you that i do not have myself. and i cannot say at this moment that the events in china are going to contribute immediately to the end of the war in vietnam.q. mr. president, would you discuss the reports that there has been a decline in the infiltration rate to the south, to say whether you think the bombing has had any effect on this?the president. i stated in my baltimore speech in early 1965 what we expected to come from the bombing.we felt that it would improve the morale of the people in south vietnam who felt that they had almost lost the war.we felt that it would make the north vietnamese pay a much heavier price for what they were doing.and we felt that it would make the infiltration more difficult.we think it has achieved all of those expressed purposes.we cannot speak with cold assurance on the infiltration and the numbers each day, or each week, or each month.in some quarters of the year our indications are that they increase. in other periods of the year, the next quarter, they may go down some.i know of nothing that i can conclude as highly significant from the guesses and the estimates that we have made.q. mr. president, we have said in the past that we would be willing to suspend the bombing of north vietnam in exchange for some suitable step by the other side. are you prepared at all to tell us what kind of other steps the other side should take for this suspension of bombing?the president. just almost any step.as far as we can see, they have not taken any yet.and we would be glad to explore any reciprocal action that they or any of their spokesmen would care to suggest.we have made one proposal after the other. we would like to have a cease-fire. we would be very glad to stop our bombing, as we have on two previous occasions, if we could have any indication of reciprocal action.but as of now they have given none. and i assume they are willing to give none until i hear further.q. mr. president, last fall your image was described in some very harsh terms. some saw it as arrogant and not to be believed. but lately these terms have switched to something much more sympathetic and you have been seen lately by many as an underdog.you have been president for more than 3 years. how do you feel about the job, and, if you can bear to tell us, how do you feel about us in the press?the president. well, i have not given a lot of thought to you in the press. we have our problems with the press twice a day at our regular briefings. i try to meet with them at least twice a month, in some manner. and almost every day i see a collection of them on one subject or the other about something that interests them.i think our system requires that, and i always try to reciprocate their understanding.now as for being president, i can only add to what i said the first day i was in this office: i am going to do the very best i can. i need all the help that i can get. i think the country, and the congress, and the other nations of the world have been very willing to be reasonable in their relations with me.i think all in all we have succeeded in obtaining some of our objectives.i go to bed every night feeling that i have failed that day because i could not end the conflict in vietnam.i do have disappointments and moments of distress, as i think every president has had.but i am not complaining.and if you can endure it in the press, i will try to endure it in the presidency.q. have you been able to take a reading of the new congress? is it perceptively more conservative than the last one?the president. yes, i think it is quite a different congress. i think it is going to be a more partisan congress. and i think that it is going to be more difficult to obtain favorable action on administration measures. i said after the first congress after the election in 1964 that the president\\'s mandate rarely lasted longer than 6 months, and i hoped that we could get most of the pledges we made in our platform enacted as soon as possible.i have never tabulated it, but i believe senator mansfield made the statement that the congress has enacted about 85 percent of our platform.we still have some other things to pass. we will win some and we will lose some. we will try to work out an area of agreement where we can take some modified language in certain legislation we have to pass.i don\\'t want to anticipate more difficulty than i need to.i am going to do with the congress like i am trying to do with our adversaries in other places in the world: i am going to say to the minority party, which i do think appears to be able to find fault with almost our every act, that i want to meet them halfway, and i want their cooperation. i want their help. because i don\\'t believe it is good for the country to have partisan political in-fighting all the time. we ought to reserve a few weeks before the election for that, and then all of us work for america the rest of the time.i hope and believe that most members of the congress will feel that way.q. mr. president, for some time you have been talking about building bridges to the countries of eastern europe. despite the appeals of this government, the czechoslovakian government has sentenced an american citizen to what we believe to be a rather harsh punishment.how does this affect your thinking on building these bridges to the communist eastern european countries?the president. there are many obstacles that come in the way in our attempt to reach all of our objectives. i regret very much the incident to which your refer. i am very hopeful that the government concerned will take appropriate, just, and fair action.i am still determined that, notwithstanding some difficulties that may arise from time to time, that this is in the overall best interests of this country. and i am going to continue to try to work toward that goal.q. mr. president, the foreign minister in north vietnam has said that if the united states stopped bombing the north.would you consider a mere willingness to talk peace to be enough of a step on their part to halt bombing or would some military move be necessarythe president. i have seen nothing that any of them have said that indicates any seriousness on their part. i am awaiting any offer they might care to make.they know that we are in contact with them. i cannot speak for them. but i am very anxious for them to make any proposal. and we will give it very prompt and serious consideration.q. recently experts have testified at the senate foreign relations committee that the whole threat of communism has changed a great deal since world war i[ and that it is quite a different picture now. do you agree that the communist threat is sufficiently different?the president. yes. we still have our problems, but i think they change from time to time. and i think there have been material changes in the thinking of various countries and their approach to their relations to other nations since world war ii.i am very hopeful that we can continue to try to evolve a satisfactory formula for getting along in this world. and i am encouraged in that hope every day. i see more encouraging signs than i do discouraging ones along that line.q. since the election of last november, a number of governors and other people have criticized the efforts or lack of efforts of the democratic party and the national committee.when mr. staebler left the white house the other day he said important things are happening within the national committee.can you tell us what is happening within the democratic party?the president. i did not see mr. staebler. i do not know what he refers to. i think he would be a better person to make that reply than i am.the democratic national committee has a very competent chairman, vice chairman, chairman of the finance committee, and the deputy chairman. all of those people were in the committee when i came into the presidency. while they have only had one national campaign since that time, it was very satisfactory so far as i am concerned.and i think some people have used the committee as a kind of whipping boy--some of them that really did not understand the functions of the committee. i have worked on both the national committee, as an officer, and the congressional committee, as an officer, for many years.it has never been the function of the national committee to take over the congressional elections. we support them. we work with them. we aid them every way we can in the national committee.but there are not many congressmen that want the democratic national chairman to manage their campaigns in their local districts. and for that reason, we have a congressional committee and we have a senatorial committee.it is my judgment that those committees are well run, well operated. they did a good job this year. and i know the democratic national committee gave them more support and more assistance and more effort than we have given in any period in our history.so i do not know exactly what they are referring to. i think if they had a knowledge of the situation, they would not feel as badly as they do about the present membership.thank you, mr. president. '"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts[500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "max() arg is an empty sequence",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-51aa2ba410a1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0;31m#print(\"Maximum words {}\".format(MAX_NB_WORDS))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mMAX_NB_WORDS\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mMAX_NB_WORDS\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind_max_nb_words\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtexts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-9-51aa2ba410a1>\u001b[0m in \u001b[0;36mfind_max_nb_words\u001b[0;34m(texts)\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0msents\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenize\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msent_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0mlocal_max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msents\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0;32mif\u001b[0m   \u001b[0mlocal_max\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mMAX_NB_WORDS\u001b[0m  \u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m             \u001b[0mMAX_NB_WORDS\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mlocal_max\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: max() arg is an empty sequence"
     ]
    }
   ],
   "source": [
    "\n",
    "    \n",
    "def find_max_nb_words(texts):\n",
    "    MAX_NB_WORDS = 0\n",
    "    for text in texts:\n",
    "        sents = tokenize.sent_tokenize(text)\n",
    "        \n",
    "        local_max = max(list(map(len, sents)))\n",
    "        if   local_max > MAX_NB_WORDS  :\n",
    "            MAX_NB_WORDS =  local_max\n",
    "        #print(\"Maximum words {}\".format(MAX_NB_WORDS))\n",
    "    return MAX_NB_WORDS\n",
    "MAX_NB_WORDS = find_max_nb_words(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "MAX_NB_WORDS = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'MAX_NB_WORDS' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-acaa9847a714>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msub\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0;34m'\\s+'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m' '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#remove extra and trailing spaces\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0mnorm_texts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnormalize_corpus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtexts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMAX_NB_WORDS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'MAX_NB_WORDS' is not defined"
     ]
    }
   ],
   "source": [
    "def normalize_corpus(text, replace_period=False):\n",
    "    import string \n",
    "    sents = tokenize.sent_tokenize(text)\n",
    "    sents = map(lambda x: x.replace('.',' '), sents)\n",
    "    local_max = max(map(len, sents))\n",
    "    if   local_max > MAX_NB_WORDS:\n",
    "        MAX_NB_WORDS =  max(map(len, sents))\n",
    "    print(\"Maximum words {}\".format(MAX_NB_WORDS))\n",
    "    text = ' . '.join(sents)      \n",
    "    for char in string.punctuation:\n",
    "        if not replace_period and char=='.':\n",
    "            text = text.replace(char, ' . ') #text.replace(char, ' ' + char + ' ')\n",
    "        else:\n",
    "            text = text.replace(char, ' ') #text.replace(char, ' ' + char + ' ')\n",
    "    text = re.sub(r'[^\\x00-\\x7F]+',' ', text) #remove non-ASCII chars\n",
    "    text = re.sub( '\\s+', ' ', text).lstrip().rstrip() #remove extra and trailing spaces\n",
    "    return text.lower()\n",
    "norm_texts = list(map(normalize_corpus, texts, MAX_NB_WORDS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "norm_texts[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 'MAX_NB_WORDS' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-16676cab1b93>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnormalize_corpus\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtexts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-10-acaa9847a714>\u001b[0m in \u001b[0;36mnormalize_corpus\u001b[0;34m(text, replace_period)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0msents\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msents\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mlocal_max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msents\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0;32mif\u001b[0m   \u001b[0mlocal_max\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mMAX_NB_WORDS\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m         \u001b[0mMAX_NB_WORDS\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msents\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Maximum words {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMAX_NB_WORDS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnboundLocalError\u001b[0m: local variable 'MAX_NB_WORDS' referenced before assignment"
     ]
    }
   ],
   "source": [
    "normalize_corpus(texts[500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2665, 11080, 10013, 1927, 81929, 62451, 51770, 54751, 5014, 6845]\n"
     ]
    }
   ],
   "source": [
    "MAX_NB_WORDS = 100\n",
    "len(texts)\n",
    "mini_test = texts[:10]\n",
    "print(list(map(len, mini_test)))\n",
    "MAX_SEQUENCE_LENGTH = 100\n",
    "MAX_SENTENCES = 100\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def pad_dense_list(speech, maxsentence):\n",
    "    \n",
    "    each_sub_len = len(speech[0])\n",
    "    Z = np.zeros((maxsentence, each_sub_len))\n",
    "    #print(\"Shape of Z{}, list {}\", Z.shape, len(speech))\n",
    "    for index, row in enumerate(speech):\n",
    "        if (index >= maxsentence):\n",
    "            break\n",
    "        \n",
    "        Z[index] = row\n",
    "    #print(Z) \n",
    "    return Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def preprocess_text(mini_test):\n",
    "    #mini_test = \"mini test. hello world.\"\n",
    "    tokenizer = Tokenizer(nb_words=5)\n",
    "    tokenizer.fit_on_texts(mini_test)\n",
    "    text_encoded = np.zeros((len(texts),MAX_SENTENCES,MAX_SEQUENCE_LENGTH))\n",
    "    #print(text_encoded.shape)\n",
    "    word_index = tokenizer.word_index\n",
    "    for enu, speech in enumerate(mini_test):\n",
    "        sents = tokenize.sent_tokenize(speech)\n",
    "        if(len(sents) == 0):\n",
    "            continue\n",
    "        sequences = tokenizer.texts_to_sequences(sents)\n",
    "        \n",
    "        #print(len(sequences))\n",
    "        #print('Found %s unique tokens.' % len(word_index))\n",
    "        data = pad_sequences(sequences, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "        text_encoded[enu] = (pad_dense_list(data, 100))\n",
    "    return word_index, text_encoded\n",
    "word_index, text_encoded = preprocess_text(texts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(862, 100, 100)\n"
     ]
    }
   ],
   "source": [
    "# First Speech encoding\n",
    "data = text_encoded\n",
    "labels = np.asarray(labels)\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  0., ...,  1.,  2.,  1.],\n",
       "       [ 0.,  0.,  0., ...,  2.,  1.,  2.],\n",
       "       [ 0.,  0.,  0., ...,  3.,  3.,  1.],\n",
       "       ..., \n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new_data = data\n",
    "\n",
    "data = data.reshape(data.shape[0], data.shape[1]*data.shape[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(862, 10000)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "data = np.zeros((800, 1000))\n",
    "labels = np.zeros(800)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of data tensor: (862, 10000)\n",
      "Shape of label tensor: (862,)\n"
     ]
    }
   ],
   "source": [
    "print('Shape of data tensor:', data.shape)\n",
    "print('Shape of label tensor:', labels.shape)\n",
    "# split the data into a training set and a validation set\n",
    "indices = np.arange(data.shape[0])\n",
    "np.random.shuffle(indices)\n",
    "data = data[indices]\n",
    "# labels = labels[indices]\n",
    "VALIDATION_SPLIT = 0.2\n",
    "nb_validation_samples = int(VALIDATION_SPLIT * data.shape[0])\n",
    "x_train = data[:-nb_validation_samples]\n",
    "y_train = labels[:-nb_validation_samples]\n",
    "x_val = data[-nb_validation_samples:]\n",
    "y_val = labels[-nb_validation_samples:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HC01113D21_PRES_PRE_DATES.DAT\r\n",
      "HC01113D21_PRES_PRE_DATES_12.DTA\r\n",
      "HL01113D21_BSSE.DAT\r\n",
      "HL01113D21_BSSE.DTA\r\n",
      "HL01113D21_BSSE_12.DTA\r\n",
      "SC01113D21_PRE_DATES.DAT\r\n",
      "SC01113D21_PRE_DATES_12.DTA\r\n",
      "SL01113D21_BSSE.DAT\r\n",
      "SL01113D21_BSSE_12.DTA\r\n",
      "\u001b[34mUserTextNN\u001b[m\u001b[m\r\n",
      "UserTextNN.zip\r\n",
      "e051633798e34e2b0b0e6360cf470d4e.torrent\r\n",
      "folders_to_presidents.csv\r\n",
      "get_presidents_labels.ipynb\r\n",
      "\u001b[34mglove.6B\u001b[m\u001b[m\r\n",
      "glove.6B.zip\r\n",
      "\u001b[34mhan-keras\u001b[m\u001b[m\r\n",
      "presidents.csv\r\n",
      "presidents2.csv\r\n",
      "presidents_with_labels.csv\r\n",
      "raw-data-to-embedding-pipeline.ipynb\r\n",
      "\u001b[34mrepos\u001b[m\u001b[m\r\n"
     ]
    }
   ],
   "source": [
    "!ls ../../"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 400000 word vectors.\n"
     ]
    }
   ],
   "source": [
    "embeddings_index = {}\n",
    "GLOVE_DIR = '../../glove.6B/'\n",
    "f = open(os.path.join(GLOVE_DIR, 'glove.6B.100d.txt'))\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:], dtype='float32')\n",
    "    embeddings_index[word] = coefs\n",
    "f.close()\n",
    "\n",
    "print('Found %s word vectors.' % len(embeddings_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "EMBEDDING_DIM = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "embedding_matrix = np.zeros((len(word_index) + 1, EMBEDDING_DIM))\n",
    "for word, i in word_index.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        # words not found in embedding index will be all-zeros.\n",
    "        embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "862\n"
     ]
    }
   ],
   "source": [
    "print(len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.layers import Embedding\n",
    "\n",
    "embedding_layer = Embedding(len(word_index) + 1,\n",
    "                            EMBEDDING_DIM,\n",
    "                            weights=[embedding_matrix],\n",
    "                            input_length=data.shape[1],\n",
    "                            trainable=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_train = y_train.reshape((-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "690\n"
     ]
    }
   ],
   "source": [
    "print(len(x_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "862"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sequence_input = Input(shape=(data.shape[1],), dtype='int32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "embedded_sequences = embedding_layer(sequence_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "embedded_sequences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_array = np.random.randint(1000, size=(32, 20*10)) #batch = 32, sent = 20, words = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 200)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tp = np.reshape(input_array,(32,200))\n",
    "tp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "embedding_10 (Embedding)         (None, 200, 64)       64000       embedding_input_9[0][0]          \n",
      "====================================================================================================\n",
      "Total params: 64000\n",
      "____________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(1000, 64, input_length=200))\n",
    "# the model will take as input an integer matrix of size (batch, input_length).\n",
    "# the largest integer (i.e. word index) in the input should be no larger than 999 (vocabulary size).\n",
    "# now model.output_shape == (None, 10, 64), where None is the batch dimension.\n",
    "\n",
    "# input_array = np.random.randint(1000, size=(32, 10))\n",
    "\n",
    "model.compile('rmsprop', 'mse')\n",
    "print(model.summary())\n",
    "output_array = model.predict(np.reshape(input_array,(32,200)))\n",
    "# assert output_array.shape == (32, 10, 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "from keras.layers  import TimeDistributed, TimeDistributedDense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 20, 10)"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25, 20, 10)"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_array[:25].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6, 1, 6, 5, 1, 5, 6, 2, 3, 2, 6, 2, 4, 1, 1, 4, 5, 6, 5, 5, 1, 6, 2,\n",
       "       1, 6])"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.randint(1,7,25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.randint(1,7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25, 200)\n",
      "(25,)\n",
      "(7, 200)\n",
      "(7,)\n"
     ]
    }
   ],
   "source": [
    "x_train = input_array[:25]\n",
    "x_val = input_array[25:]\n",
    "y_train = np.random.randint(1,7,25)\n",
    "y_val = np.random.randint(1,7,7)\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(x_val.shape)\n",
    "print(y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "embedding_matrix = np.random.randint(0,999,(1000,64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "embedding_122 (Embedding)        (None, 200, 64)       0           embedding_input_118[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "reshape_105 (Reshape)            (None, 20, 10, 64)    0           embedding_122[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "lambda_78 (Lambda)               (None, 1, 20, 64)     0           reshape_105[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "timedistributed_53 (TimeDistribu (None, 1, 20, 100)    66000       lambda_78[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "reshape_106 (Reshape)            (None, 20, 100)       0           timedistributed_53[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "lambda_79 (Lambda)               (None, 100)           0           reshape_106[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "reshape_107 (Reshape)            (None, 100)           0           lambda_79[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dense_19 (Dense)                 (None, 7)             707         reshape_107[0][0]                \n",
      "====================================================================================================\n",
      "Total params: 66707\n",
      "____________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "embedding_layer = Embedding(1000, 64, weights=[embedding_matrix],input_length=200,trainable=False)\n",
    "# model.add(Embedding(1000, 64, input_length=200, weights = weights))\n",
    "model.add(embedding_layer)\n",
    "model.add(Reshape((20, 10, 64,), input_shape=(200,64,)))\n",
    "# model.add(TimeDistributed(LSTM(100, input_shape=(32, 20, 64), return_sequences=True)))\n",
    "model.add(Lambda(lambda x: K.mean(x, axis=2, keepdims=True), output_shape=lambda s: (s[0], 1, s[1],s[3])))\n",
    "model.add(TimeDistributed(LSTM(100, input_shape=(20, 64), return_sequences=True)))\n",
    "model.add(Reshape((20,100), input_shape=(1,20,100)))\n",
    "model.add(Lambda(lambda x: K.mean(x, axis=1, keepdims=True), output_shape=lambda s: (s[0], s[2])))\n",
    "model.add(Reshape((100,)))\n",
    "model.add(Dense(7, input_dim=100, activation='softmax'))\n",
    "model.compile(loss='sparse_categorical_crossentropy',optimizer='rmsprop',metrics=['acc'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 25 samples, validate on 7 samples\n",
      "Epoch 1/10\n",
      "25/25 [==============================] - 2s - loss: 1.7752 - acc: 0.2800 - val_loss: 1.7855 - val_acc: 0.0000e+00\n",
      "Epoch 2/10\n",
      "25/25 [==============================] - 2s - loss: 1.7465 - acc: 0.2800 - val_loss: 1.8196 - val_acc: 0.0000e+00\n",
      "Epoch 3/10\n",
      "25/25 [==============================] - 2s - loss: 1.7253 - acc: 0.2400 - val_loss: 1.8010 - val_acc: 0.0000e+00\n",
      "Epoch 4/10\n",
      "25/25 [==============================] - 2s - loss: 1.7254 - acc: 0.2000 - val_loss: 1.8097 - val_acc: 0.0000e+00\n",
      "Epoch 5/10\n",
      "25/25 [==============================] - 1s - loss: 1.7182 - acc: 0.3200 - val_loss: 1.8405 - val_acc: 0.0000e+00\n",
      "Epoch 6/10\n",
      "25/25 [==============================] - 2s - loss: 1.7250 - acc: 0.2000 - val_loss: 1.8570 - val_acc: 0.0000e+00\n",
      "Epoch 7/10\n",
      "25/25 [==============================] - 1s - loss: 1.7078 - acc: 0.2400 - val_loss: 1.8539 - val_acc: 0.2857\n",
      "Epoch 8/10\n",
      "25/25 [==============================] - 2s - loss: 1.6969 - acc: 0.3600 - val_loss: 1.8285 - val_acc: 0.0000e+00\n",
      "Epoch 9/10\n",
      "25/25 [==============================] - 2s - loss: 1.7164 - acc: 0.3200 - val_loss: 1.8894 - val_acc: 0.0000e+00\n",
      "Epoch 10/10\n",
      "25/25 [==============================] - 2s - loss: 1.7016 - acc: 0.2800 - val_loss: 1.8764 - val_acc: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x13a263f10>"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, validation_data=(x_val, y_val),nb_epoch=10, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "embedding_99 (Embedding)         (None, 200, 64)       64000       embedding_input_95[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "reshape_51 (Reshape)             (None, 20, 10, 64)    0           embedding_99[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "timedistributed_30 (TimeDistribu (None, 20, 10, 100)   66000       reshape_51[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "lambda_36 (Lambda)               (None, 1, 20, 100)    0           timedistributed_30[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "timedistributed_31 (TimeDistribu (None, 1, 20, 100)    80400       lambda_36[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "reshape_52 (Reshape)             (None, 20, 100)       0           timedistributed_31[0][0]         \n",
      "====================================================================================================\n",
      "Total params: 210400\n",
      "____________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "# model.add(embedding_layer)\n",
    "#sequence_input = Input(shape=(data.shape[1],), dtype='int32')\n",
    "model.add(Embedding(1000, 64, input_length=200))\n",
    "# model.add(TimeDistributed(Embedding(1000, 64, input_length=200), input_shape = (32,20,10)))\n",
    "# model.add(TimeDistributed(Reshape((20,10,64), input_shape=(200,64))))\n",
    "model.add(Reshape((20, 10, 64,), input_shape=(200,64,)))\n",
    "model.add(TimeDistributed(LSTM(100, input_shape=(32, 20, 64), return_sequences=True)))\n",
    "model.add(Lambda(lambda x: K.mean(x, axis=2, keepdims=True), output_shape=lambda s: (s[0], 1, s[1],s[3])))\n",
    "# model.add(TimeDistributed(Reshape((20, 10, 64,), input_shape=(200,64,))))\n",
    "model.add(TimeDistributed(LSTM(100, input_shape=(32, 20, 64), return_sequences=True)))\n",
    "model.add(Reshape((20,100), input_shape=(1,20,100)))\n",
    "# model.compile(loss='sparse_categorical_crossentropy',optimizer='rmsprop',metrics=['acc'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "Exception",
     "evalue": "Input 0 is incompatible with layer timedistributed_8: expected ndim=3, found ndim=4",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-115-e3eb40f4be03>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mReshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLambda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTimeDistributed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLambda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;31m# model.add(LSTM(64,  return_sequences = True))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# model.add(TimeDistributed(#Dense(8), input_shape=(20, 64)))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/keras/models.pyc\u001b[0m in \u001b[0;36madd\u001b[0;34m(self, layer)\u001b[0m\n\u001b[1;32m    322\u001b[0m                  output_shapes=[self.outputs[0]._keras_shape])\n\u001b[1;32m    323\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 324\u001b[0;31m             \u001b[0moutput_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    325\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_tensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m                 raise Exception('All layers in a Sequential model '\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/keras/engine/topology.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, x, mask)\u001b[0m\n\u001b[1;32m    496\u001b[0m         \u001b[0;31m# Raise exceptions in case the input is not compatible\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    497\u001b[0m         \u001b[0;31m# with the input_spec set at build time.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 498\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massert_input_compatibility\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    499\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    500\u001b[0m         \u001b[0minput_tensors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/keras/engine/topology.pyc\u001b[0m in \u001b[0;36massert_input_compatibility\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    413\u001b[0m                                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m': expected ndim='\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    414\u001b[0m                                         \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m', found ndim='\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 415\u001b[0;31m                                         str(K.ndim(x)))\n\u001b[0m\u001b[1;32m    416\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mspec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    417\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mspec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mException\u001b[0m: Input 0 is incompatible with layer timedistributed_8: expected ndim=3, found ndim=4"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "# model.add(embedding_layer)\n",
    "#sequence_input = Input(shape=(data.shape[1],), dtype='int32')\n",
    "model.add(Embedding(1000, 64, input_length=200))\n",
    "#embedded_sequences = embedding_layer(sequence_input)\n",
    "model.add(Reshape((20, 10, 64,), input_shape=(200,64,)))\n",
    "model.add(Lambda(lambda x: K.mean(x, axis=2, keepdims=True), output_shape=lambda s: (s[0], s[1],s[3])))\n",
    "model.add(TimeDistributed(Lambda(lambda x: K.mean(x, axis=2, keepdims=True), output_shape=lambda s: (s[0], s[1],s[3])), input_shape=(32,20,10,64)))\n",
    "# model.add(LSTM(64,  return_sequences = True))\n",
    "# model.add(TimeDistributed(#Dense(8), input_shape=(20, 64)))\n",
    "#reshaped = ))(embedded_sequences)\n",
    "#embedding_sum = Lambda(lambda x: K.sum(x, axis=1), output_shape=lambda s: (s[0], s[2]))(reshaped)\n",
    "#print(embedding_sum.summary())\n",
    "#x = LSTM(100)(embedding_sum)\n",
    "#preds = Dense(7, activation='sigmoid')(embedded_sequences)\n",
    "#model = Model(sequence_input, preds)\n",
    "model.compile(loss='sparse_categorical_crossentropy',optimizer='rmsprop',metrics=['acc'])\n",
    "print(model.summary())\n",
    "# happy learning!\n",
    "#model.fit(x_train, y_train, validation_data=(x_val, y_val),\n",
    "#    nb_epoch=2, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "embedding_22 (Embedding)         (None, 200, 64)       64000       embedding_input_21[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "reshape_2 (Reshape)              (None, 20, 10, 64)    0           embedding_22[0][0]               \n",
      "====================================================================================================\n",
      "Total params: 64000\n",
      "____________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "# model.add(embedding_layer)\n",
    "model.add(Embedding(1000, 64, input_length=200))\n",
    "model.add(Reshape((20,10,64,), input_shape=(200,64,)))\n",
    "model.compile('rmsprop', 'mse')\n",
    "print(model.summary())\n",
    "output_array = model.predict(np.reshape(input_array,(32,200)))\n",
    "# assert output_array.shape == (32, 10, 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() takes exactly 2 arguments (1 given)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-78-e0a4bdba372e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0msequence_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mInput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'int32'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0membedded_sequences\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0membedding_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msequence_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mReshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membedded_sequences\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;31m# x = LSTM(100)(x) #optional for now\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLambda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#attention to replace this\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: __init__() takes exactly 2 arguments (1 given)"
     ]
    }
   ],
   "source": [
    "sequence_input = Input(shape=(data.shape[1],), dtype='int32')\n",
    "embedded_sequences = embedding_layer(sequence_input)\n",
    "x = Reshape(output_shape = (20,10,64), input_shape=(200,64))(embedded_sequences)\n",
    "# x = LSTM(100)(x) #optional for now\n",
    "x = Lambda(lambda x: K.sum(x, axis=1), output_shape=lambda s: (s[0], s[2]))(x) #attention to replace this\n",
    "x = LSTM(100)(x)\n",
    "x = Lambda(lambda x: K.sum(x, axis=1), output_shape=lambda s: (s[0],))(x) #attention to replace this\n",
    "preds = Dense(8, activation='sigmoid')(x)\n",
    "\n",
    "model = Model(sequence_input, preds)\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
    "model.fit(x_train, y_train, validation_data=(x_val, y_val),\n",
    "          nb_epoch=2, batch_size=10)\n",
    "\n",
    "\n",
    "# model = Sequential()\n",
    "# model.add(Embedding(40k,100,input_size=10000))\n",
    "# model.add(Reshape(output_shape = (100,100), input_shape=(10000,)))\n",
    "# model.add(Lambda(lambda x: K.sum(x, axis=1), output_shape=lambda s: (s[0], s[2])))\n",
    "# model.add(LSTM(100))\n",
    "# model.add(Lambda(lambda x: K.sum(x, axis=1), output_shape=lambda s: (s[0],)))\n",
    "# model.add(Dense(7, activation='sigmoid'))\n",
    "# model.compile(loss='sparse_categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
    "\n",
    "# preds = Dense(7, activation='sigmoid')(x)\n",
    "# model = Model(sequence_input, preds)\n",
    "# model.compile(loss='sparse_categorical_crossentropy',\n",
    "#               optimizer='rmsprop',\n",
    "#               metrics=['acc'])\n",
    "\n",
    "# # happy learning!\n",
    "# model.fit(x_train, y_train, validation_data=(x_val, y_val),\n",
    "#           nb_epoch=2, batch_size=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Experiment with sequence classification \n",
    "from keras.datasets import imdb\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.preprocessing import sequence\n",
    "# fix random seed for reproducibility\n",
    "np.random.seed(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "top_words = 5000\n",
    "(X_train, y_train), (X_test, y_test) = imdb.load_data(nb_words=top_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "(X_train_imdb, y_train_imdb), (X_test_imdb, y_test_imdb)  = (X_train, y_train), (X_test, y_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(y_train_imdb[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "max_review_length = 500\n",
    "X_train = sequence.pad_sequences(X_train, maxlen=max_review_length)\n",
    "X_test = sequence.pad_sequences(X_test, maxlen=max_review_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(X_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "embedding_vecor_length = 32\n",
    "model = Sequential()\n",
    "model.add(Embedding(top_words, embedding_vecor_length, input_length=max_review_length))\n",
    "model.add(LSTM(100))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "print(model.summary())\n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), nb_epoch=3, batch_size=64)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
